[["index.html", "MTH3045: Statistical Computing: Exercises 1 Chapter 1 exercises", " MTH3045: Statistical Computing: Exercises Dr. Ben Youngman b.youngman@exeter.ac.uk Laver 817; ext. 2314 16/01/2023 1 Chapter 1 exercises Generate a sample of \\(n = 20\\) \\(N(1, 3^2)\\) random variates, and without using mean(), var() or sd() write R functions to calculate the sample mean, \\(\\bar x\\), sample variance, \\(s^2\\), and sample standard deviation, \\(s\\), where \\[ \\bar x = \\dfrac{1}{n} \\sum_{i = 1}^n x_i \\text{ and } s^2 = \\dfrac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar x)^2. \\] Note than sum() may be used. Solution &gt; n &lt;- 20 &gt; y &lt;- rnorm(n, 1, 3) &gt; &gt; # mean &gt; mean2 &lt;- function(x) { + # function to calculate mean of a vector + # x is a vector + # returns a scalar + sum(x) / length(x) + } &gt; &gt; mean2(y) ## [1] 1.435992 &gt; # check it works &gt; all.equal(mean(y), mean2(y)) ## [1] TRUE &gt; # variance &gt; var2 &lt;- function(x) { + # function to calculate variance of a vector + # x is a vector + # returns a scalar + xbar &lt;- mean2(x) + sum((x - xbar)^2) / (length(x) - 1) + } &gt; &gt; var2(y) ## [1] 11.95993 &gt; # check it works &gt; all.equal(var(y), var2(y)) ## [1] TRUE &gt; # standard deviation &gt; sd2 &lt;- function(x) { + # function to calculate standard deviation of a vector + # x is a vector + # returns a scalar + sqrt(var2(x)) + } &gt; &gt; sd2(y) ## [1] 3.458313 &gt; # check it works &gt; all.equal(sd(y), sd2(y)) ## [1] TRUE Note that above for mean2() we’ve not used a for loop. A for loop can be used, but usually if on cna be avoided, then it should. Then for var2() we’ve re-used mean2() and for sd2() we’ve re-used var2(). It’s often a good idea to re-use functions. In this case, we break the function sd2() into various smaller functions, which can often be good practice, as whether the final function is correct can be assessed by whether the simpler functions it comprises are correct. Consider computing \\(\\text{Pr}(Z \\geq z) = 1 - \\Phi(z)\\) where \\(Z \\sim \\text{Normal}(0, 1)\\), or, for short, \\(Z \\sim N(0, 1)\\). For \\(z = 0, 0.5, 1, 1.5, 2, \\ldots\\) compute this in R in three different ways using the following three commands &gt; pnorm(z, lower.tail = FALSE) &gt; 1 - pnorm(z) &gt; pnorm(-z) and find the lowest value of \\(z\\) for which the three don’t give the same answer. Solution &gt; z &lt;- seq(0, 7, by = .5) &gt; cbind( + z, + pnorm(z, lower.tail = FALSE), + 1 - pnorm(z), + pnorm(-z) + ) ## z ## [1,] 0.0 5.000000e-01 5.000000e-01 5.000000e-01 ## [2,] 0.5 3.085375e-01 3.085375e-01 3.085375e-01 ## [3,] 1.0 1.586553e-01 1.586553e-01 1.586553e-01 ## [4,] 1.5 6.680720e-02 6.680720e-02 6.680720e-02 ## [5,] 2.0 2.275013e-02 2.275013e-02 2.275013e-02 ## [6,] 2.5 6.209665e-03 6.209665e-03 6.209665e-03 ## [7,] 3.0 1.349898e-03 1.349898e-03 1.349898e-03 ## [8,] 3.5 2.326291e-04 2.326291e-04 2.326291e-04 ## [9,] 4.0 3.167124e-05 3.167124e-05 3.167124e-05 ## [10,] 4.5 3.397673e-06 3.397673e-06 3.397673e-06 ## [11,] 5.0 2.866516e-07 2.866516e-07 2.866516e-07 ## [12,] 5.5 1.898956e-08 1.898956e-08 1.898956e-08 ## [13,] 6.0 9.865876e-10 9.865877e-10 9.865876e-10 ## [14,] 6.5 4.016001e-11 4.015999e-11 4.016001e-11 ## [15,] 7.0 1.279813e-12 1.279865e-12 1.279813e-12 Above we see that for \\(z = 6.0\\), the second approximation to the standard normal tail probability doesn’t give the same answer as the other two approximations (although the discrepancy is tiny). The formula \\(\\text{Var}(Y) = \\text{E}(Y^2) - [\\text{E}(Y)]^2\\) is sometimes called the ‘short-cut’ variance formula, i.e. a short-cut for \\(\\text{Var}(Y) = \\text{E}[Y - \\text{E}(Y)]^2\\). Compare computing the biased version of \\(\\text{Var}(Y)\\) using the two formulae above for the samples y1 and y2 below. &gt; y1 &lt;- 1:10 &gt; y2 &lt;- y1 + 1e9 Solution We’ll start with a function to calculate the short-cut formula &gt; bvar1 &lt;- function(x) { + # function to calculate short-cut variance + # x is a vector + # returns a scalar + mean(x^2) - mean(x)^2 + } and the we’ll write a function to calculate the other formula. &gt; bvar2 &lt;- function(x) { + # function to calculate variance + # x is a vector + # returns a scalar + mean((x - mean(x))^2) + } For y1 we have &gt; bvar1(y1) ## [1] 8.25 &gt; bvar2(y1) ## [1] 8.25 and so both formulae give the same answer, but for y2 we have &gt; bvar1(y2) ## [1] 0 &gt; bvar2(y2) ## [1] 8.25 and see that they don’t. The short-cut formula is clearly wrong, bcause the variance of a sample doesn’t change if we add a constant, which is the only difference between y1 and y2. (We’ll learn about the cause of this in Chapter 2.) "],["chapter-2-exercises.html", "2 Chapter 2 exercises", " 2 Chapter 2 exercises Compute \\(\\pi + \\text{e}\\), where \\(\\pi = 3.1415927 \\times 10^0\\) and \\(\\text{e} = 2.7182818 \\times 10^0\\), using floating point addition in base 10, working to five decimal places. Solution As \\(\\pi\\) and \\(\\text{e}\\) have a common exponent, we sum their mantissas, i.e. \\[\\begin{align*} \\pi + \\text{e} &amp;= (3.14159 \\times 10^0) + (2.71828 \\times 10^0)\\\\ &amp;= 5.85987 \\times 10^0 \\end{align*}\\] Now compute \\(10^6\\pi + \\text{e}\\), using floating point addition in base 10, now working to seven decimal places. Solution We first need to put the numbers on a common exponent, which is that of \\(10^6 \\pi\\). \\[\\begin{align*} 10^6 \\pi &amp;= 3.1415927 \\times 10^6\\\\ \\text{e} &amp; = 2.7182818 \\times 10^0 = 0.0000027 \\times 10^6. \\end{align*}\\] Then summing their mantissas gives \\[\\begin{align*} 10^6 \\pi + \\text{e} &amp;= (3.1415927 \\times 10^6) + (2.7182818 \\times 10^0)\\\\ &amp;= (3.1415927 \\times 10^6) + (0.0000027 \\times 10^6)\\\\ &amp;= (3.1415927 + 0.0000027) \\times 10^6\\\\ &amp;= 3.1415954 \\times 10^6. \\end{align*}\\] What would happen if we computed \\(10^6\\pi + \\text{e}\\) using a base 10 floating point representation, but only worked with five decimal places? Solution If we put \\(2.7182818 \\times 10^0\\) onto the exponent \\(10^6\\) we get \\(0.00000 \\times 10^6\\) to five decimal places, and so \\(\\text{e}\\) becomes negligible alongside \\(10^6 \\pi\\) if we only work to five decimal places. Write \\(2\\pi\\) in binary form using single- and double precision arithmetic. [Hint: I recommend you consider the binary forms for \\(\\pi\\) given in the lecture notes, and you might also use bit2decimal() from the lecture notes to check your answer.] Solution The key here is to note that we want to calculate \\(\\pi \\times 2\\). As we have a number in the form \\(S \\times (1 + F) \\times 2^{E - e}\\), then we just need to raise \\(E\\) by one. For both single- and double-precision, this corresponds to changing the last zero in the 0s and 1s for the \\(E\\) term to a one. &gt; bit2decimal &lt;- function(x, e, dp = 20) { + # function to convert bits to decimal form + # x: the bits as a character string, with appropriate spaces + # e: the excess + # dp: the decimal places to report the answer to + bl &lt;- strsplit(x, &#39; &#39;)[[1]] # split x into S, E and F components by spaces + # and then into a list of three character vectors, each element one bit + bl &lt;- lapply(bl, function(z) as.integer(strsplit(z, &#39;&#39;)[[1]])) + names(bl) &lt;- c(&#39;S&#39;, &#39;E&#39;, &#39;F&#39;) # give names, to simplify next few lines + S &lt;- (-1)^bl$S # calculate sign, S + E &lt;- sum(bl$E * 2^c((length(bl$E) - 1):0)) # ditto for exponent, E + F &lt;- sum(bl$F * 2^(-c(1:length(bl$F)))) # and ditto to fraction, F + z &lt;- S * 2^(E - e) * (1 + F) # calculate z + out &lt;- format(z, nsmall = dp) # use format() for specific dp + # add (S, E, F) as attributes, for reference + attr(out, &#39;(S,E,F)&#39;) &lt;- c(S = S, E = E, F = F) + out + } &gt; bit2decimal(&#39;0 10000001 10010010000111111011011&#39;, 127) ## [1] &quot;6.28318548202514648438&quot; ## attr(,&quot;(S,E,F)&quot;) ## S E F ## 1.0000000 129.0000000 0.5707964 &gt; bit2decimal(&#39;0 10000000001 1001001000011111101101010100010001000010110100011000&#39;, 1023) ## [1] &quot;6.28318530717958623200&quot; ## attr(,&quot;(S,E,F)&quot;) ## S E F ## 1.0000000 1025.0000000 0.5707963 Find the calculation error in R of \\(b - a\\) where \\(a = 10^{16}\\) and \\(b = 10^{16} + \\exp(0.5)\\). Solution &gt; a &lt;- 1e16 &gt; b &lt;- 1e16 + exp(.5) &gt; b - a ## [1] 2 Create the following: The row vector \\[ \\mathbf{a} = (2, 4, 6), \\] the \\(2 \\times 3\\) matrix \\[ \\mathbf{B} = \\left(\\begin{array}{ccc} 6 &amp; 5 &amp; 4\\\\ 3 &amp; 2 &amp; 1\\end{array}\\right) \\] and a list with first element \\(\\mathbf{a}\\) and second element \\(\\mathbf{B}\\), and an arbitrary (i.e. with whatever values you like) \\(5 \\times 3 \\times 2\\) array with a 'name' attribute that is 'array1'. \\(~\\) For each of the above, consider whether your code could be simpler. Solution &gt; a &lt;- t(c(2, 4, 6)) &gt; B &lt;- matrix(6:1, 2, byrow = TRUE) &gt; l &lt;- list(a, B) &gt; arr &lt;- array(rnorm(30), c(5, 3, 2)) &gt; attr(arr, &#39;name&#39;) &lt;- &#39;array1&#39; &gt; arr ## , , 1 ## ## [,1] [,2] [,3] ## [1,] -0.22082848 0.07798049 2.35561582 ## [2,] -0.86731638 -0.17796264 -0.04856896 ## [3,] -0.08223767 0.91340827 0.57926010 ## [4,] -1.12801962 0.92897607 -0.68947695 ## [5,] 1.23291492 -0.04606696 0.90004808 ## ## , , 2 ## ## [,1] [,2] [,3] ## [1,] -0.7653358 -1.1561969 -1.8801783 ## [2,] -0.4455043 -0.3707302 -0.5268794 ## [3,] -0.6881160 1.7878535 0.5595031 ## [4,] -2.8078170 -0.5762095 1.9709363 ## [5,] -0.7589532 0.2925063 -1.2573699 ## ## attr(,&quot;name&quot;) ## [1] &quot;array1&quot; Produce a \\(3 \\times 4 \\times 4 \\times 2\\) array containing Uniform(0, 1) random variates and compute the mean over its second and third margins using apply(..., ..., means) and rowMeans() or colMeans(). Solution &gt; arr &lt;- array(NA, c(3, 4, 4, 2)) &gt; arr[] &lt;- runif(prod(dim(arr))) # saves names to get the number right &gt; apply(arr, 2:3, mean) ## [,1] [,2] [,3] [,4] ## [1,] 0.5412984 0.3164106 0.5290190 0.5859542 ## [2,] 0.4790915 0.7778092 0.4955934 0.4519054 ## [3,] 0.6438975 0.5685883 0.3768004 0.7742829 ## [4,] 0.5312454 0.6337979 0.5185317 0.5974344 &gt; rowMeans(aperm(arr, c(2, 3, 1, 4)), dims = 2) ## [,1] [,2] [,3] [,4] ## [1,] 0.5412984 0.3164106 0.5290190 0.5859542 ## [2,] 0.4790915 0.7778092 0.4955934 0.4519054 ## [3,] 0.6438975 0.5685883 0.3768004 0.7742829 ## [4,] 0.5312454 0.6337979 0.5185317 0.5974344 &gt; colMeans(aperm(arr, c(1, 4, 2, 3)), dims = 2) ## [,1] [,2] [,3] [,4] ## [1,] 0.5412984 0.3164106 0.5290190 0.5859542 ## [2,] 0.4790915 0.7778092 0.4955934 0.4519054 ## [3,] 0.6438975 0.5685883 0.3768004 0.7742829 ## [4,] 0.5312454 0.6337979 0.5185317 0.5974344 Create a 3-element list of vectors comprising Uniform(0, 1) variates of length 3, 5 and 7, respectively. Solution &gt; lst &lt;- list(runif(3), runif(5), runif(7)) Create another list in which the vectors above are sorted into descending order. Solution &gt; lst2 &lt;- lapply(lst, sort, decreasing = TRUE) Then create a vector comprising the minimum of each vector in the list, and another stating which element is the minimum. [Hint: for the latter you may want to consult the ‘See Also’ part of the min() function’s help file.] Solution &gt; sapply(lst, min) ## [1] 0.11054058 0.20906353 0.02678557 &gt; sapply(lst, which.min) ## [1] 1 3 6 Use a for() loop to produce the following. [Hint: the function paste() might be useful.] ## [1] &quot;iteration 1&quot; ## [1] &quot;iteration 2&quot; ## [1] &quot;iteration 3&quot; ## [1] &quot;iteration 4&quot; ## [1] &quot;iteration 5&quot; ## [1] &quot;iteration 6&quot; ## [1] &quot;iteration 7&quot; ## [1] &quot;iteration 8&quot; ## [1] &quot;iteration 9&quot; ## [1] &quot;iteration 10&quot; Solution &gt; for (i in 1:10) print(paste(&#39;iteration&#39;, i)) ## [1] &quot;iteration 1&quot; ## [1] &quot;iteration 2&quot; ## [1] &quot;iteration 3&quot; ## [1] &quot;iteration 4&quot; ## [1] &quot;iteration 5&quot; ## [1] &quot;iteration 6&quot; ## [1] &quot;iteration 7&quot; ## [1] &quot;iteration 8&quot; ## [1] &quot;iteration 9&quot; ## [1] &quot;iteration 10&quot; Consider the following two infinite series that represent \\(\\pi\\).\\[\\begin{align*} \\pi &amp;= 4 \\left[1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\frac{1}{9} - \\frac{1}{11} + \\frac{1}{13} -\\cdots\\right]\\\\ \\pi &amp;= 3 + \\frac{4}{2 \\times 3 \\times 4} - \\frac{4}{4 \\times 5 \\times 6} + \\frac{4}{6 \\times 7 \\times 8} - \\frac{4}{8 \\times 9 \\times 10} + \\cdots \\end{align*}\\] Use a while() loop to find which converges to pi in R to within \\(\\epsilon_m^{1/3}\\) using the fewest terms, where \\(\\epsilon_m\\) is R’s machine tolerance. Solution Here’s the first approximation… &gt; quarter_pi &lt;- 1 &gt; terms1 &lt;- 1 &gt; denom &lt;- 3 &gt; multiplier &lt;- -1 &gt; my_pi &lt;- 4 * quarter_pi &gt; while(abs(my_pi - pi) &gt; .Machine$double.eps^(1/3)) { + terms1 &lt;- terms1 + 1 + quarter_pi &lt;- quarter_pi + multiplier / denom + my_pi &lt;- 4 * quarter_pi + denom &lt;- denom + 2 + multiplier &lt;- -1 * multiplier + } &gt; terms1 ## [1] 165141 …and here’s the second approximation… &gt; my_pi &lt;- 3 &gt; terms2 &lt;- 2 &gt; denoms &lt;- c(2, 3, 4) &gt; multiplier &lt;- 1 &gt; while(abs(my_pi - pi) &gt; .Machine$double.eps^(1/3)) { + my_pi &lt;- my_pi + multiplier * 4 / prod(denoms) + denoms &lt;- denoms + 2 + multiplier &lt;- -1 * multiplier + terms2 &lt;- terms2 + 1 + } &gt; terms2 ## [1] 36 Write a function based on a for() loop to calculate the cumulative sum of a vector, \\(\\bf y\\), i.e. so that its \\(i\\)th value, \\(y_i\\) say, is \\[y_i = \\sum_{j = 1}^i x_j.\\] Solution Either of the following two functions are options (although others exist). &gt; my_cumsum &lt;- function(x) { + # function 1 to calculate cumulative sum of a vector + # x is a vector + # returns a vector of length length(x) + out &lt;- numeric(length(x)) + for (i in 1:length(x)) { + out[i] &lt;- sum(x[1:i]) + } + out + } &gt; &gt; my_cumsum2 &lt;- function(x) { + # function 2 to calculate cumulative sum of a vector + # x is a vector + # returns a vector of length length(x) + out &lt;- x + for (i in 2:length(x)) { + out[i] &lt;- out[i] + out[i - 1] + } + out + } We see that both perform the same calculation. &gt; x &lt;- runif(10) &gt; cumsum(x) ## [1] 0.07552154 0.21783228 0.96615073 1.65599550 2.22400871 2.69252642 ## [7] 3.04584137 3.49323280 4.12646915 4.51356362 &gt; my_cumsum(x) ## [1] 0.07552154 0.21783228 0.96615073 1.65599550 2.22400871 2.69252642 ## [7] 3.04584137 3.49323280 4.12646915 4.51356362 &gt; my_cumsum2(x) ## [1] 0.07552154 0.21783228 0.96615073 1.65599550 2.22400871 2.69252642 ## [7] 3.04584137 3.49323280 4.12646915 4.51356362 Then benchmark its execution time against R’s vectorised function cumsum() for summing 1000 iid \\(Uniform[0, 1]\\) random variables. Solution &gt; x &lt;- runif(1e3) &gt; microbenchmark::microbenchmark( + cumsum(x), + my_cumsum(x), + my_cumsum2(x) + ) ## Unit: nanoseconds ## expr min lq mean median uq max neval ## cumsum(x) 769 867.5 1228.35 1142 1294.5 4715 100 ## my_cumsum(x) 1777980 1824995.5 2318183.04 1848706 1901259.5 8326976 100 ## my_cumsum2(x) 60717 61326.0 63295.42 62975 64686.0 69806 100 To start a board game, a player must throw three sixes using a conventional die. Write a function to simulate this, which returns the total number of throws that the player has taken. Solution &gt; sixes1 &lt;- function() { + # function to simulate number of throws needed + # to reach three sixes + # n is an integer + # returns total number of throws taken + out &lt;- sample(1:6, 3, replace = TRUE) + while(sum(out == 6) &lt; 3) { + out &lt;- c(out, sample(1:6, 1)) + } + return(length(out)) + } Then use 1000 simulations to empirically estimate the distribution of the number of throws needed. Solution &gt; samp1 &lt;- replicate(1e3, sixes1()) &gt; table(samp1) ## samp1 ## 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ## 3 11 28 27 35 39 42 44 47 61 53 48 46 37 38 49 32 45 25 33 30 24 22 23 16 17 ## 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 46 47 49 51 53 55 56 57 60 61 ## 15 13 16 8 6 3 10 9 6 4 5 5 2 2 6 4 1 1 2 2 1 1 1 1 1 &gt; hist(samp1, xlab = &#39;Number of throws&#39;, main = &#39;Histogram of number of throws&#39;) Figure 2.1: Histogram of empirical distribution of number of throws for starting method 1. I think you’ll agree that this would be a rather dull board game! It is therefore proposed that a player should instead throw two consecutive sixes. Write a function to simulate this new criterion, and estimate its distribution empirically. Solution &gt; sixes2 &lt;- function() { + # function to simulate number of throws needed + # for two consecutive sixes + # n is an integer + # returns total number of throws taken + out &lt;- sample(1:6, 2, replace = TRUE) + cond &lt;- TRUE + while(cond) { + if (sum(out[1:(length(out) - 1)] + out[2:length(out)] == 12) &gt; 0) { + cond &lt;- FALSE + } else { + out &lt;- c(out, sample(1:6, 1)) + } + } + return(length(out)) + } &gt; sixes2() ## [1] 86 Then use 1000 simulations to empirically estimate the distribution of the number of throws needed. Solution &gt; samp2 &lt;- replicate(1e3, sixes2()) &gt; table(samp2) ## samp2 ## 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## 32 23 28 18 16 21 15 20 23 19 9 24 25 9 10 23 20 12 16 21 ## 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ## 15 22 21 10 20 18 7 10 14 9 8 9 11 11 17 12 18 6 11 9 ## 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 ## 18 13 4 9 7 13 14 4 5 9 2 6 3 7 5 8 4 10 11 7 ## 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 ## 5 4 7 4 6 4 3 3 4 8 5 6 6 3 5 5 2 3 2 1 ## 82 83 84 86 87 88 90 91 93 95 96 97 98 99 100 101 102 103 105 106 ## 3 2 3 2 2 5 1 1 3 3 1 1 3 4 3 1 1 1 1 1 ## 107 108 109 111 112 113 114 115 117 119 121 122 124 125 126 128 129 130 131 132 ## 1 1 1 4 1 1 1 1 3 3 1 2 2 2 2 1 1 1 2 1 ## 134 135 137 138 139 141 142 143 145 146 147 150 153 154 155 156 157 161 166 177 ## 3 2 1 1 1 4 2 1 1 2 1 1 1 2 1 2 2 1 1 1 ## 186 199 200 231 242 292 297 ## 1 1 2 1 1 1 1 &gt; hist(samp2, xlab = &#39;Number of throws&#39;, main = &#39;Histogram of number of throws&#39;) Figure 2.2: Histogram of empirical distribution of number of throws for starting method 2. By comparing sample mean starting numbers of throws, which starting criterion should get a player into the game quickest? Solution &gt; mean(samp1) - mean(samp2) ## [1] -22.442 So the second approach, by comparing means, takes more throws before the game can begin. Consider the following two functions for calculating \\[d_i = x_{i + 1} - x_i, \\hspace{2cm} i = 1, \\ldots, n - 1\\] where \\({\\bf x}&#39; = (x_1, \\ldots, x_n)\\). &gt; diff1 &lt;- function(x) { + # function to calculate differences of a vector + # based on a for loop + # x is a vector + # returns a vector of length (length(x) - 1) + out &lt;- numeric(length(x) - 1) + for (i in 1:(length(x) - 1)) { + out[i] &lt;- x[i + 1] - x[i] + } + out + } &gt; diff2 &lt;- function(x) { + # function to calculate differences of a vector + # based on vectorisation + # x is a vector + # returns a vector of length (length(x) - 1) + id &lt;- 1:(length(x) - 1) + x[id + 1] - x[id] + } The first, diff1() uses a straightforward for() loop to calculate \\(d_i\\), for \\(i = 1, \\ldots, n - 1\\), whereas diff2() could be seen to be a vectorised alternative. Benchmark the two for a vector of \\(n = 1000\\) iid \\(N(0, 1)\\) random variates by comparing the median difference in execution time. Solution &gt; x &lt;- rnorm(1000) &gt; microbenchmark::microbenchmark( + diff1(x), + diff2(x) + ) ## Unit: microseconds ## expr min lq mean median uq max neval ## diff1(x) 58.519 61.3755 96.96706 62.327 63.0310 3522.392 100 ## diff2(x) 8.367 8.9190 29.48372 9.161 9.4225 2020.424 100 The following function assesses whether all elements is a logical vector are TRUE. &gt; all2 &lt;- function(x) { + # function to calculate whether all elements are TRUE + # returns a scalar + # x is a logical vector + sum(x) == length(x) + } Calculate the following and benchmark all2() against R’s built-in function all(), which does the same. &gt; n &lt;- 1e4 &gt; x1 &lt;- !logical(n) Solution &gt; all2(x1) ## [1] TRUE &gt; all(x1) ## [1] TRUE &gt; microbenchmark::microbenchmark( + all2(x1), + all(x1) + ) ## Unit: microseconds ## expr min lq mean median uq max neval ## all2(x1) 5.007 5.100 16.90681 5.1550 5.2070 1179.006 100 ## all(x1) 11.361 11.401 12.13829 11.4305 13.5985 18.968 100 We see that both take a similar amount of time. Now swap the first element of x1 so that it’s FALSE and repeat the benchmarking. Solution &gt; x1[1] &lt;- FALSE &gt; all2(x1) ## [1] FALSE &gt; all(x1) ## [1] FALSE &gt; microbenchmark::microbenchmark( + all2(x1), + all(x1) + ) ## Unit: nanoseconds ## expr min lq mean median uq max neval ## all2(x1) 4733 4846 4981.88 4908 4941.5 10433 100 ## all(x1) 143 158 199.19 206 212.0 462 100 Now all2() is much slower. This is because it’s performed a calculation on the entire x1 vector, whereas all() has stopped as soon as it’s found a FALSE. Evaluate the function any2() below against R’s built-in function any() similarly. &gt; any2 &lt;- function(x) { + # function to calculate whether any elements are TRUE + # returns a scalar + # x is a logical vector + sum(x) &gt; 0 + } Solution &gt; x2 &lt;- logical(n) &gt; any2(x2) ## [1] FALSE &gt; any(x2) ## [1] FALSE &gt; microbenchmark::microbenchmark( + any2(x2), + any(x2) + ) ## Unit: microseconds ## expr min lq mean median uq max neval ## any2(x2) 4.741 4.8720 15.43042 5.0655 5.143 1045.033 100 ## any(x2) 13.006 13.0515 13.65272 13.5940 13.636 28.526 100 We again see that both take a similar amount of time. Now swap the first element of x2 so that it’s FALSE and repeat the benchmarking. Solution &gt; x2[1] &lt;- TRUE &gt; microbenchmark::microbenchmark( + any2(x2), + any(x2) + ) ## Unit: nanoseconds ## expr min lq mean median uq max neval ## any2(x2) 4912 5050.5 5157.21 5098 5140.0 11002 100 ## any(x2) 148 158.0 200.36 208 228.5 570 100 This time any2() is much slower, for similar reasoning to all2() being much slower than all(), except that any() is stopped when it reaches a TRUE. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
