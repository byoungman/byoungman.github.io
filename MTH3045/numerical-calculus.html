<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Numerical Calculus | MTH3045: Statistical Computing</title>
  <meta name="description" content="4 Numerical Calculus | MTH3045: Statistical Computing" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Numerical Calculus | MTH3045: Statistical Computing" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Numerical Calculus | MTH3045: Statistical Computing" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="matrix-based-computing.html"/>
<link rel="next" href="optimisation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#module-outline"><i class="fa fa-check"></i><b>1.1</b> Module outline</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#lectures-practical-classes"><i class="fa fa-check"></i><b>1.2</b> Lectures / practical classes</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#office-hours"><i class="fa fa-check"></i><b>1.3</b> Office hours</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i><b>1.4</b> Resources</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.5</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#assessment"><i class="fa fa-check"></i><b>1.6</b> Assessment</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#motivating-example"><i class="fa fa-check"></i><b>1.7</b> Motivating example</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#exploratory-and-refresher-exercises"><i class="fa fa-check"></i><b>1.8</b> Exploratory and refresher exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch2.html"><a href="ch2.html"><i class="fa fa-check"></i><b>2</b> Statistical computing in <code>R</code></a>
<ul>
<li class="chapter" data-level="2.1" data-path="ch2.html"><a href="ch2.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="ch2.html"><a href="ch2.html#mathematics-by-computer"><i class="fa fa-check"></i><b>2.2</b> Mathematics by computer</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ch2.html"><a href="ch2.html#positional-number-systems"><i class="fa fa-check"></i><b>2.2.1</b> Positional number systems</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch2.html"><a href="ch2.html#a-historical-aside-on-exact-representations-of-integers"><i class="fa fa-check"></i><b>2.2.2</b> A historical aside on exact representations of integers</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch2.html"><a href="ch2.html#floating-point-representation"><i class="fa fa-check"></i><b>2.2.3</b> Floating point representation</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch2.html"><a href="ch2.html#single-precision-arithmetic"><i class="fa fa-check"></i><b>2.2.4</b> Single-precision arithmetic</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch2.html"><a href="ch2.html#double-precision-arithmetic"><i class="fa fa-check"></i><b>2.2.5</b> Double-precision arithmetic</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch2.html"><a href="ch2.html#flops-floating-point-operations"><i class="fa fa-check"></i><b>2.2.6</b> Flops: floating point operations</a></li>
<li class="chapter" data-level="2.2.7" data-path="ch2.html"><a href="ch2.html#some-useful-terminology"><i class="fa fa-check"></i><b>2.2.7</b> Some useful terminology</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch2.html"><a href="ch2.html#the-history-of-r"><i class="fa fa-check"></i><b>2.3</b> The history of <code>R</code></a></li>
<li class="chapter" data-level="2.4" data-path="ch2.html"><a href="ch2.html#why-r"><i class="fa fa-check"></i><b>2.4</b> Why <code>R</code>?</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ch2.html"><a href="ch2.html#basics"><i class="fa fa-check"></i><b>2.4.1</b> Basics</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch2.html"><a href="ch2.html#data-structures"><i class="fa fa-check"></i><b>2.4.2</b> Data structures</a></li>
<li class="chapter" data-level="2.4.3" data-path="ch2.html"><a href="ch2.html#some-useful-r-functions"><i class="fa fa-check"></i><b>2.4.3</b> Some useful <code>R</code> functions</a></li>
<li class="chapter" data-level="2.4.4" data-path="ch2.html"><a href="ch2.html#control-structures"><i class="fa fa-check"></i><b>2.4.4</b> Control structures</a></li>
<li class="chapter" data-level="2.4.5" data-path="ch2.html"><a href="ch2.html#vectorisation"><i class="fa fa-check"></i><b>2.4.5</b> Vectorisation</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch2.html"><a href="ch2.html#good-practice"><i class="fa fa-check"></i><b>2.5</b> Good practice</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ch2.html"><a href="ch2.html#useful-tips-to-remember-when-coding"><i class="fa fa-check"></i><b>2.5.1</b> Useful tips to remember when coding</a></li>
<li class="chapter" data-level="2.5.2" data-path="ch2.html"><a href="ch2.html#debugging"><i class="fa fa-check"></i><b>2.5.2</b> Debugging</a></li>
<li class="chapter" data-level="2.5.3" data-path="ch2.html"><a href="ch2.html#profiling-and-benchmarking"><i class="fa fa-check"></i><b>2.5.3</b> Profiling and benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch2.html"><a href="ch2.html#compiled-code-with-rcpp"><i class="fa fa-check"></i><b>2.6</b> Compiled code with <code>Rcpp</code></a></li>
<li class="chapter" data-level="2.7" data-path="ch2.html"><a href="ch2.html#bibliographic-notes"><i class="fa fa-check"></i><b>2.7</b> Bibliographic notes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html"><i class="fa fa-check"></i><b>3</b> Matrix-based computing</a>
<ul>
<li class="chapter" data-level="3.1" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#motivation"><i class="fa fa-check"></i><b>3.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#definitions"><i class="fa fa-check"></i><b>3.2</b> Definitions</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#matrix-properties"><i class="fa fa-check"></i><b>3.2.1</b> Matrix properties</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#special-matrices"><i class="fa fa-check"></i><b>3.3</b> Special matrices</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#diagonal-band-diagonal-and-triangular-matrices"><i class="fa fa-check"></i><b>3.3.1</b> Diagonal, band-diagonal and triangular matrices</a></li>
<li class="chapter" data-level="3.3.2" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#sparse-matrices"><i class="fa fa-check"></i><b>3.3.2</b> Sparse matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#systems-of-linear-equations"><i class="fa fa-check"></i><b>3.4</b> Systems of linear equations</a></li>
<li class="chapter" data-level="3.5" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#matrix-decompositions"><i class="fa fa-check"></i><b>3.5</b> Matrix decompositions</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#cholesky-decomposition"><i class="fa fa-check"></i><b>3.5.1</b> Cholesky decomposition</a></li>
<li class="chapter" data-level="3.5.2" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#eigen-decomposition"><i class="fa fa-check"></i><b>3.5.2</b> Eigen-decomposition</a></li>
<li class="chapter" data-level="3.5.3" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#singular-value-decomposition"><i class="fa fa-check"></i><b>3.5.3</b> Singular value decomposition</a></li>
<li class="chapter" data-level="3.5.4" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#qr-decomposition"><i class="fa fa-check"></i><b>3.5.4</b> QR decomposition</a></li>
<li class="chapter" data-level="3.5.5" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#computational-costs-of-matrix-decompostions"><i class="fa fa-check"></i><b>3.5.5</b> Computational costs of matrix decompostions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#sherman-morrison-formula-woodbury-matrix-identity"><i class="fa fa-check"></i><b>3.6</b> Sherman-Morrison formula / Woodbury matrix identity</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#woodburys-formula"><i class="fa fa-check"></i><b>3.6.1</b> Woodbury’s formula</a></li>
<li class="chapter" data-level="3.6.2" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#sherman-morrison-woodbury-formula"><i class="fa fa-check"></i><b>3.6.2</b> Sherman-Morrison-Woodbury formula</a></li>
<li class="chapter" data-level="3.6.3" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#sherman-morrison-formula"><i class="fa fa-check"></i><b>3.6.3</b> Sherman-Morrison formula</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="matrix-based-computing.html"><a href="matrix-based-computing.html#bibliographic-notes-1"><i class="fa fa-check"></i><b>3.7</b> Bibliographic notes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="numerical-calculus.html"><a href="numerical-calculus.html"><i class="fa fa-check"></i><b>4</b> Numerical Calculus</a>
<ul>
<li class="chapter" data-level="4.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#motivation-1"><i class="fa fa-check"></i><b>4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#numerical-differentiation"><i class="fa fa-check"></i><b>4.2</b> Numerical Differentiation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#differentiation-definitions"><i class="fa fa-check"></i><b>4.2.1</b> Differentiation definitions</a></li>
<li class="chapter" data-level="4.2.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#differentiation-rules"><i class="fa fa-check"></i><b>4.2.2</b> Differentiation rules</a></li>
<li class="chapter" data-level="4.2.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#finite-differencing"><i class="fa fa-check"></i><b>4.2.3</b> Finite-differencing</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#quadrature"><i class="fa fa-check"></i><b>4.3</b> Quadrature</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#midpoint-rule"><i class="fa fa-check"></i><b>4.3.1</b> Midpoint rule</a></li>
<li class="chapter" data-level="4.3.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#simpsons-rule"><i class="fa fa-check"></i><b>4.3.2</b> Simpson’s rule</a></li>
<li class="chapter" data-level="4.3.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#gaussian-quadrature"><i class="fa fa-check"></i><b>4.3.3</b> Gaussian quadrature</a></li>
<li class="chapter" data-level="4.3.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#one-dimensional-numerical-integration-in-r"><i class="fa fa-check"></i><b>4.3.4</b> One-dimensional numerical integration in <code>R</code></a></li>
<li class="chapter" data-level="4.3.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#multi-dimensional-quadrature"><i class="fa fa-check"></i><b>4.3.5</b> Multi-dimensional quadrature</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="numerical-calculus.html"><a href="numerical-calculus.html#laplaces-method"><i class="fa fa-check"></i><b>4.4</b> Laplace’s method</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="numerical-calculus.html"><a href="numerical-calculus.html#an-aside-on-taylor-series-in-one-dimension"><i class="fa fa-check"></i><b>4.4.1</b> An aside on Taylor series in one dimension</a></li>
<li class="chapter" data-level="4.4.2" data-path="numerical-calculus.html"><a href="numerical-calculus.html#definition-1"><i class="fa fa-check"></i><b>4.4.2</b> Definition</a></li>
<li class="chapter" data-level="4.4.3" data-path="numerical-calculus.html"><a href="numerical-calculus.html#laplaces-method-for-multiple-dimensions"><i class="fa fa-check"></i><b>4.4.3</b> Laplace’s method for multiple dimensions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="numerical-calculus.html"><a href="numerical-calculus.html#monte-carlo-integration"><i class="fa fa-check"></i><b>4.5</b> Monte Carlo integration</a></li>
<li class="chapter" data-level="4.6" data-path="numerical-calculus.html"><a href="numerical-calculus.html#bibliographic-notes-2"><i class="fa fa-check"></i><b>4.6</b> Bibliographic notes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="optimisation.html"><a href="optimisation.html"><i class="fa fa-check"></i><b>5</b> Optimisation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="optimisation.html"><a href="optimisation.html#root-finding"><i class="fa fa-check"></i><b>5.1</b> Root finding</a></li>
<li class="chapter" data-level="5.2" data-path="optimisation.html"><a href="optimisation.html#one-dimensional-optimisation-in-r"><i class="fa fa-check"></i><b>5.2</b> One-dimensional optimisation in <code>R</code></a></li>
<li class="chapter" data-level="5.3" data-path="optimisation.html"><a href="optimisation.html#newtons-method-in-one-dimension"><i class="fa fa-check"></i><b>5.3</b> Newton’s method in one-dimension</a></li>
<li class="chapter" data-level="5.4" data-path="optimisation.html"><a href="optimisation.html#newtons-multi-dimensional-method"><i class="fa fa-check"></i><b>5.4</b> Newton’s multi-dimensional method</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="optimisation.html"><a href="optimisation.html#taylors-theorem-multivariate"><i class="fa fa-check"></i><b>5.4.1</b> Taylor’s theorem (multivariate)</a></li>
<li class="chapter" data-level="5.4.2" data-path="optimisation.html"><a href="optimisation.html#newtons-method-in-r"><i class="fa fa-check"></i><b>5.4.2</b> Newton’s method in <code>R</code></a></li>
<li class="chapter" data-level="5.4.3" data-path="optimisation.html"><a href="optimisation.html#gradient-descent"><i class="fa fa-check"></i><b>5.4.3</b> Gradient descent</a></li>
<li class="chapter" data-level="5.4.4" data-path="optimisation.html"><a href="optimisation.html#line-search"><i class="fa fa-check"></i><b>5.4.4</b> Line search</a></li>
<li class="chapter" data-level="5.4.5" data-path="optimisation.html"><a href="optimisation.html#quasi-newton-methods"><i class="fa fa-check"></i><b>5.4.5</b> Quasi-Newton methods</a></li>
<li class="chapter" data-level="5.4.6" data-path="optimisation.html"><a href="optimisation.html#quasi-newton-methods-in-r"><i class="fa fa-check"></i><b>5.4.6</b> Quasi-Newton methods in <code>R</code></a></li>
<li class="chapter" data-level="5.4.7" data-path="optimisation.html"><a href="optimisation.html#sec:nelder"><i class="fa fa-check"></i><b>5.4.7</b> Nelder-Mead polytope method</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="optimisation.html"><a href="optimisation.html#global-optimisation"><i class="fa fa-check"></i><b>5.5</b> Global optimisation</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="optimisation.html"><a href="optimisation.html#stochastic-optimisation"><i class="fa fa-check"></i><b>5.5.1</b> Stochastic optimisation</a></li>
<li class="chapter" data-level="5.5.2" data-path="optimisation.html"><a href="optimisation.html#simulated-annealing"><i class="fa fa-check"></i><b>5.5.2</b> Simulated annealing</a></li>
<li class="chapter" data-level="5.5.3" data-path="optimisation.html"><a href="optimisation.html#simulated-annealing-in-r"><i class="fa fa-check"></i><b>5.5.3</b> Simulated annealing in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="optimisation.html"><a href="optimisation.html#bibliographic-notes-3"><i class="fa fa-check"></i><b>5.6</b> Bibliographic notes</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MTH3045: Statistical Computing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="numerical-calculus" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Numerical Calculus<a href="numerical-calculus.html#numerical-calculus" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="motivation-1" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Motivation<a href="numerical-calculus.html#motivation-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="example">
<p><span id="exm:unlabeled-div-62" class="example"><strong>Example 4.1  </strong></span>In statistics, we often rely on the Normal distribution with pdf
<span class="math display">\[
\phi(x; \mu, \sigma^2) = \dfrac{1}{\sqrt{2 \pi \sigma^2}} \exp\left[-\dfrac{(x - \mu)^2}{2 \sigma^2}\right]
\]</span>
and cdf
<span class="math display">\[
\Phi(x; \mu, \sigma^2) = \int_{-\infty}^x \phi(x; \mu, \sigma^2) \text{d} x.
\]</span>
Unfortunately no closed form exists for <span class="math inline">\(\Phi(x; \mu, \sigma^2)\)</span>. However, if <span class="math inline">\(x\)</span>, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are stored in <code>R</code> as <code>x</code>, <code>mu</code> and <code>sigma</code>, we can still evaluate <span class="math inline">\(\Phi(x; \mu, \sigma^2)\)</span> with <code>pnorm(x, mu, sigma)</code>. This is one example of a frequently-occurring situation in which we somehow want to evaluate an intractable integral. This raises the question: are there generic methods that let us evaluate intractable integrals? The answer is often <em>numerical integration</em>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-63" class="remark"><em>Remark</em>. </span>In this chapter, we’ll consider generic methods for integration, i.e. that work in many scenarios. Sometimes, such as evaluating <span class="math inline">\(\Phi(x; \mu, \sigma^2)\)</span>, specific algorithms will give more accurate results. This is what <code>R</code> does for <code>pnorm()</code>.</p>
</div>
</div>
<div id="numerical-differentiation" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Numerical Differentiation<a href="numerical-calculus.html#numerical-differentiation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Chapter 5 we will cover optimisation of functions, such as numerically finding maximum likelihood estimates when analytical solutions aren’t available. We’ll see that supplying derivatives can considerably improve estimation, typically in terms of reducing computation time. Here we’ll cover some useful results in terms of differentiation of matrices, which will later prove useful. No knowledge of analytical matrix calculus beyond these results will be needed for MTH3045. The matrix cookbook <span class="citation">(Petersen and Pedersen 2012)</span>, however, can provide you with a much more thorough set of differentiation rules, should you ever need them.</p>
<div id="differentiation-definitions" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Differentiation definitions<a href="numerical-calculus.html#differentiation-definitions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-64" class="definition"><strong>Definition 4.1  (Gradient operator) </strong></span>Consider <span class="math inline">\(f : \mathbb{R}^n \to \mathbb{R}\)</span>, which we’ll consider a function of vector <span class="math inline">\(\mathbf{x} = (x_1, \ldots, x_n)^\text{T}\)</span>. The <strong>gradient operator</strong>, <span class="math inline">\(\nabla\)</span>, is defined as
<span class="math display">\[
\nabla f(\mathbf{x}) =
\left(\begin{array}{c}
\frac{\partial f(\mathbf{x})}{\partial x_1}\\
\frac{\partial f(\mathbf{x})}{\partial x_2}\\
\vdots \\
\frac{\partial f(\mathbf{x})}{\partial x_n}\\
\end{array}\right).
\]</span></p>
</div>
<p>Note that in MTH3045 we will have no cause to consider multivariate functions, i.e. to consider <span class="math inline">\(\mathbf{f} : \mathbb{R}^n \to \mathbb{R}^m\)</span>, for <span class="math inline">\(m &gt; 1\)</span>.</p>
<!-- :::{.definition name="Jacobian"} -->
<!-- Consider $\mathbf{f} : \mathbb{R}^n \to \mathbb{R}^m$, which we'll consider a function of vector $\mathbf{x} = (x_1, \ldots, x_n)^\text{T}$. The **Jacobian matrix**, $\mathbf{J}$, is the $n \times m$ matrix with $(i, j)$th entry $J_{ij} = \partial f_j / \partial x_i$, for $i = 1, \ldots, n$ and $j = 1, \ldots, m$, i.e.  -->
<!-- \[ -->
<!-- \mathbf{J} =  -->
<!-- \left(\begin{array}{cccc} \frac{\partial \mathbf{f}}{\partial x_1} & \frac{\partial \mathbf{f}}{\partial x_2} & \cdots & \frac{\partial \mathbf{f}}{\partial x_n}\end{array}\right) = -->
<!-- \left(\begin{array}{cccc} -->
<!-- \frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \cdots & \frac{\partial f_1}{\partial x_n} \\ -->
<!-- \frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \cdots & \frac{\partial f_2}{\partial x_n} \\ -->
<!-- \vdots & \vdots & \ddots & \vdots  \\ -->
<!-- \frac{\partial f_m}{\partial x_1} & \frac{\partial f_m}{\partial x_2} & \cdots & \frac{\partial f_m}{\partial x_n} \\ -->
<!-- \end{array}\right) -->
<!-- \] -->
<!-- ::: -->
<div class="definition">
<p><span id="def:unlabeled-div-65" class="definition"><strong>Definition 4.2  (Hessian matrix) </strong></span>Consider again <span class="math inline">\(f : \mathbb{R}^n \to \mathbb{R}\)</span>. The <strong>Hessian matrix</strong> is the matrix of second derivatives of <span class="math inline">\(f\)</span>, whereas the gradient operator considered first derivatives, and is given by
<span class="math display">\[
\nabla^2 f(\mathbf{x}) =
\left(\begin{array}{cccc}
\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_n^2} \\
\end{array}\right).
\]</span></p>
</div>
<p>The Hessian matrix plays an important role in statistics, in particular for estimating parameter uncertainty via the Fisher information, which is covered in MTH3028. In the next chapter, we’ll also see that it’s important for optimisation.</p>
<div class="remark">
<p><span id="unlabeled-div-66" class="remark"><em>Remark</em>. </span>If <span class="math inline">\(\tilde{\mathbf{x}}\)</span> is at a minimum of <span class="math inline">\(f(\mathbf{x})\)</span> then the gradient vector w.r.t. <span class="math inline">\(\mathbf{x}\)</span> should be all zero, i.e. <span class="math inline">\(\nabla f(\mathbf{x}) = \mathbf{0}\)</span> and, additionally, the Hessian matrix, i.e. <span class="math inline">\(\nabla^2 f(\mathbf{x})\)</span> should be positive definite.</p>
</div>
</div>
<div id="differentiation-rules" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Differentiation rules<a href="numerical-calculus.html#differentiation-rules" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now consider <span class="math inline">\(g : \mathbb{R}^n \to \mathbb{R}\)</span> a function of <span class="math inline">\(\bf x\)</span> that, for fixed <span class="math inline">\(\bf A\)</span>, takes the quadratic form <span class="math inline">\(g(\mathbf{x}) = \mathbf{x}^\text{T} \mathbf{Ax}\)</span> for <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(n\)</span>-vector <span class="math inline">\(\mathbf{x}\)</span>. Then
<span class="math display">\[
\nabla g(\mathbf{x}) = (\mathbf{A} + \mathbf{A}^\text{T})\mathbf{x}
~~~\text{and}~~~
\nabla^2 g(\mathbf{x}) = \mathbf{A} + \mathbf{A}^\text{T}.\]</span>
Note that in the case of symmetric <span class="math inline">\(\bf A\)</span>, <span class="math inline">\(\nabla g(\mathbf{x}) = 2\mathbf{Ax}\)</span> and <span class="math inline">\(\nabla^2 g(\mathbf{x}) = 2\mathbf{A}\)</span>.</p>
<p>Next consider <span class="math inline">\(h : \mathbb{R}^n \to \mathbb{R}\)</span> a function of <span class="math inline">\(n\)</span>-vector <span class="math inline">\(\bf x\)</span> and <span class="math inline">\(p\)</span>-vector <span class="math inline">\(y\)</span> that, for fixed <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(\bf A\)</span> and <span class="math inline">\(n \times p\)</span> matrix <span class="math inline">\(\bf B\)</span>, takes the quadratic form <span class="math inline">\(h(\mathbf{x}, \mathbf{y}) = (\mathbf{x} + \mathbf{By})^\text{T} \mathbf{A}(\mathbf{x} + \mathbf{By})\)</span>. Then
<span class="math display">\[
\dfrac{\partial h(\mathbf{x}, \mathbf{y})}{\partial \mathbf{x}} = (\mathbf{A} + \mathbf{A}^\text{T})(\mathbf{x} + \mathbf{By})~~~\text{and}~~~
\dfrac{\partial h(\mathbf{x}, \mathbf{y})}{\partial \mathbf{y}} = \mathbf{B}^T (\mathbf{A} + \mathbf{A}^\text{T}) (\mathbf{x} + \mathbf{By}),
\]</span>
and also
<span class="math display">\[
\dfrac{\partial^2 h(\mathbf{x}, \mathbf{y})}{\partial \mathbf{x} \partial \mathbf{x}^\text{T}} = \mathbf{A} + \mathbf{A}^\text{T}~~~\text{and}~~~
\dfrac{\partial^2 h(\mathbf{x}, \mathbf{y})}{\partial \mathbf{y} \partial \mathbf{y}^\text{T}} = \mathbf{B}^\text{T}(\mathbf{A} + \mathbf{A}^\text{T})\mathbf{B}.
\]</span></p>
<p>Note that above we use partial derivative notation, i.e. <span class="math inline">\(\partial\)</span>, as opposed to gradient operator notation, i.e. <span class="math inline">\(\nabla\)</span>, as the derivatives are not w.r.t. all variables.</p>
<div class="example">
<p><span id="exm:unlabeled-div-67" class="example"><strong>Example 4.2  (Maximum likelihood estimates of regression coefficients in the normal linear model via matrix calculus) </strong></span>Consider the normal linear model <span class="math inline">\(\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}\)</span>, where <span class="math inline">\(\mathbf{Y} = (Y_1, \ldots, Y_n)^\text{T}\)</span>, <span class="math inline">\(\mathbf{X}\)</span> is an <span class="math inline">\(n \times (p + 1)\)</span> design matrix, <span class="math inline">\(\boldsymbol{\beta}\)</span> is a <span class="math inline">\((p + 1)\)</span>-vector of regression coefficients, and <span class="math inline">\(\boldsymbol{\varepsilon}= (\varepsilon_1, \ldots, \varepsilon_n)^\text{T}\)</span> with independent <span class="math inline">\(\varepsilon_i \sim N(0, \sigma^2)\)</span>. The maximum likelihood estimate of <span class="math inline">\(\boldsymbol{\beta}\)</span>, denoted <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, minimises the RSS, i.e. minimises <span class="math inline">\((\mathbf{y} - \mathbf{X} \boldsymbol{\beta})^\text{T}(\mathbf{y} - \mathbf{X} \boldsymbol{\beta})\)</span> if we observe <span class="math inline">\(\mathbf{y} = (y_1, \ldots, y_n)^\text{T}\)</span>. Differentiating w.r.t. <span class="math inline">\(\boldsymbol{\beta}\)</span> gives <span class="math inline">\(-\mathbf{X}^\text{T} (\mathbf{y} - \mathbf{X} \boldsymbol{\beta}) - (\mathbf{y} - \mathbf{X} \boldsymbol{\beta})^\text{T} \mathbf{X}\)</span>, which simplifies to <span class="math inline">\(-2\mathbf{X}^\text{T} (\mathbf{y} - \mathbf{X} \boldsymbol{\beta})\)</span> as <span class="math inline">\(\mathbf{X}^\text{T} (\mathbf{y} - \mathbf{X} \boldsymbol{\beta})\)</span> and <span class="math inline">\((\mathbf{y} - \mathbf{X} \boldsymbol{\beta})^\text{T} \mathbf{X}\)</span> are both <span class="math inline">\(n\)</span>-vectors. The derivative is zero at <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> and so <span class="math inline">\(-2\mathbf{X}^\text{T} (\mathbf{y} - \mathbf{X} \hat{\boldsymbol{\beta}}) = 0\)</span>. Therefore <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is the solution of <span class="math inline">\(\mathbf{X}^\text{T} \mathbf{X} \hat{\boldsymbol{\beta}} = \mathbf{X}^\text{T} \mathbf{y}\)</span> or alternatively <span class="math inline">\(\hat{\boldsymbol{\beta}} = (\mathbf{X}^\text{T} \mathbf{X})^{-1} \mathbf{X}^\text{T} \mathbf{y}\)</span>, as we were given in Topic 3.</p>
</div>
</div>
<div id="finite-differencing" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Finite-differencing<a href="numerical-calculus.html#finite-differencing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider again <span class="math inline">\(f(\mathbf{x})\)</span>, a function of vector <span class="math inline">\(\bf x\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-68" class="definition"><strong>Definition 4.3  (Partial derivative) </strong></span>Consider <span class="math inline">\(f: \mathbb{R}^n \to \mathbb{R}\)</span> for <span class="math inline">\(n\)</span>-vector <span class="math inline">\(\bf x\)</span>. Let, <span class="math inline">\(\mathbf{e}_i\)</span> be the <span class="math inline">\(n\)</span>-vector comprising entirely zeros, except for its <span class="math inline">\(i\)</span>th element, which is one. Then the <strong>partial derivative</strong> of <span class="math inline">\(f(\mathbf{x})\)</span> w.r.t. <span class="math inline">\(x_i\)</span>, the <span class="math inline">\(i\)</span>th element of <span class="math inline">\(\bf x\)</span>, is
<span class="math display">\[
\dfrac{\partial f(\mathbf{x})}{\partial x_i} = \lim_{h \to 0} \dfrac{f(\mathbf{x} + h \mathbf{e}_i) - f(\mathbf{x})}{h}.
\]</span></p>
</div>
<p>The above definition leads us to the <strong>finite-difference</strong> partial derivative approximation</p>
<p><span class="math display">\[
\dfrac{\partial f(\mathbf{x})}{\partial x_i} \simeq \dfrac{f(\mathbf{x} + \delta \mathbf{e}_i) - f(\mathbf{x})}{\delta},
\]</span></p>
<p>where <span class="math inline">\(\delta\)</span> is small.</p>
<div class="example">
<p><span id="exm:sinfd" class="example"><strong>Example 4.3  (Finite-differencing of $\sin(x)$) </strong></span>Use finite-differencing to approximate the derivative of <span class="math inline">\(f(x) = \sin(x)\)</span> for <span class="math inline">\(x \in [0, 2\pi]\)</span>, and compare its accuracy to the true derivative.</p>
</div>
<p>First, let’s calculate <span class="math inline">\(f\)</span> and its <em>true</em> derivative, i.e. <span class="math inline">\(f&#39;(x) = \cos(x)\)</span>, and store this as <code>partial0</code> for <span class="math inline">\(\{x_i\}\)</span>, <span class="math inline">\(i = 1, \ldots, 100\)</span>, a set of equally-spaced points on <span class="math inline">\([0, 2\pi]\)</span>.</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="numerical-calculus.html#cb278-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb278-2"><a href="numerical-calculus.html#cb278-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">2</span> <span class="sc">*</span> pi, <span class="at">l =</span> <span class="dv">100</span>)</span>
<span id="cb278-3"><a href="numerical-calculus.html#cb278-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f <span class="ot">&lt;-</span> <span class="fu">sin</span>(x)</span>
<span id="cb278-4"><a href="numerical-calculus.html#cb278-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> partial0 <span class="ot">&lt;-</span> <span class="fu">cos</span>(x)</span></code></pre></div>
<p>Now we’ll set <span class="math inline">\(\delta = 10^{-6}\)</span> and calculate <span class="math inline">\(x_i + \delta\)</span>, for each <span class="math inline">\(x_i\)</span>, i.e. each element of <code>x</code>, so that the finite-difference approximation to the derivative is given by <span class="math inline">\([\sin(x_i + 10^{-6}) - \sin(x_i)] / 10^{-6}\)</span>, which is calculated below and stored as <code>partial1</code>.</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="numerical-calculus.html#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> delta1 <span class="ot">&lt;-</span> <span class="fl">1e-6</span></span>
<span id="cb279-2"><a href="numerical-calculus.html#cb279-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x1 <span class="ot">&lt;-</span> x <span class="sc">+</span> delta1</span>
<span id="cb279-3"><a href="numerical-calculus.html#cb279-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f1 <span class="ot">&lt;-</span> <span class="fu">sin</span>(x1)</span>
<span id="cb279-4"><a href="numerical-calculus.html#cb279-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> partial1 <span class="ot">&lt;-</span> (f1 <span class="sc">-</span> f) <span class="sc">/</span> delta1</span></code></pre></div>
<p>We’ll then plot the <span class="math inline">\(f&#39;(x)\)</span> against it finite-difference approximation.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="numerical-calculus.html#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">matplot</span>(x, <span class="fu">cbind</span>(partial0, partial1), <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;x&#39;</span>, <span class="at">ylab =</span> <span class="st">&quot;f&#39;(x)&quot;</span>)</span>
<span id="cb280-2"><a href="numerical-calculus.html#cb280-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">legend</span>(<span class="st">&#39;bottomleft&#39;</span>, <span class="at">lty =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,</span>
<span id="cb280-3"><a href="numerical-calculus.html#cb280-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>        <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&#39;True&#39;</span>, <span class="st">&#39;Finite-difference&#39;</span>))</span></code></pre></div>
<p><img src="main_files/figure-html/fd3-1.png" width="672" /></p>
<p>In fact, the true derivative and its finite-difference approximation are so similar that’s it’s difficult to distinguish the two, but they’re both there in the plot!</p>
<div class="remark">
<p><span id="unlabeled-div-69" class="remark"><em>Remark</em>. </span>We might be tempted to choose <span class="math inline">\(\delta\)</span> as small as possible. Suppose we were to repeat Example <a href="numerical-calculus.html#exm:sinfd">4.3</a> with <span class="math inline">\(\delta = \epsilon_m\)</span>, i.e. <code>R</code>’s machine tolerance. The following calculates the finite-difference approximation as <code>partial2</code> and plots this against the true value of <span class="math inline">\(f&#39;(x)\)</span>.</p>
</div>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="numerical-calculus.html#cb281-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> delta2 <span class="ot">&lt;-</span> .Machine<span class="sc">$</span>double.eps</span>
<span id="cb281-2"><a href="numerical-calculus.html#cb281-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x2 <span class="ot">&lt;-</span> x <span class="sc">+</span> delta2</span>
<span id="cb281-3"><a href="numerical-calculus.html#cb281-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f2 <span class="ot">&lt;-</span> <span class="fu">sin</span>(x2)</span>
<span id="cb281-4"><a href="numerical-calculus.html#cb281-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> partial2 <span class="ot">&lt;-</span> (f2 <span class="sc">-</span> f) <span class="sc">/</span> delta2</span>
<span id="cb281-5"><a href="numerical-calculus.html#cb281-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">matplot</span>(x, <span class="fu">cbind</span>(partial0, partial2), <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;x&#39;</span>, <span class="at">ylab =</span> <span class="st">&quot;f&#39;(x)&quot;</span>)</span>
<span id="cb281-6"><a href="numerical-calculus.html#cb281-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">legend</span>(<span class="st">&#39;bottomleft&#39;</span>, <span class="at">lty =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">bg =</span> <span class="st">&#39;white&#39;</span>,</span>
<span id="cb281-7"><a href="numerical-calculus.html#cb281-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>        <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&#39;True&#39;</span>, <span class="st">&#39;Finite-difference with machine tolerance&#39;</span>))</span></code></pre></div>
<p><img src="main_files/figure-html/fd4-1.png" width="672" /></p>
<p>Using <span class="math inline">\(\delta = \epsilon_m\)</span> gives a terrible approximation to <span class="math inline">\(f&#39;(x)\)</span>, which gets worse as <span class="math inline">\(x\)</span> increases. We’ve actually encountered an example <em>calculation error</em>, which was introduced in Chapter 2.</p>
<div class="example">
<p><span id="exm:mvnfd" class="example"><strong>Example 4.4  (Finite-differencing of the multivariate Normal log-likelihood) </strong></span>Find <span class="math inline">\(\partial \log f(\mathbf{y} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma}) / \partial y_i\)</span> analytically, for <span class="math inline">\(i = 1, \ldots, p\)</span>, where <span class="math inline">\(f(\mathbf{y} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span> is the <span class="math inline">\(MVN_p(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span> pdf, for arbitrary <span class="math inline">\(\mathbf{y}\)</span>, <span class="math inline">\(\boldsymbol{\mu}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. Evaluate this for <span class="math inline">\(\mathbf{y}\)</span>, <span class="math inline">\(\boldsymbol{\mu}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span> as in Example <a href="matrix-based-computing.html#exm:mvn1">3.2</a>. Then approximate the same derivative using finite-differencing.</p>
</div>
<p>The logarithm of the <span class="math inline">\(MVN_p(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span> pdf is given by
<span class="math display">\[
\log f(\mathbf{y} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma}) = -\dfrac{1}{2} \left[p \log(2 \pi) + \log(|\boldsymbol{\Sigma}|) + ({\bf y} - {\boldsymbol \mu})^\text{T} {\boldsymbol \Sigma}^{-1} ({\bf y} - {\boldsymbol \mu}) \right]
\]</span>
which we know, from Example <a href="matrix-based-computing.html#exm:mvn3">3.13</a>, we can evaluate with <code>dmvn3()</code>. Using the above properties
<span class="math display">\[
\dfrac{\partial \log f(\mathbf{y} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma})}{\partial \mathbf{y}} = -{\boldsymbol \Sigma}^{-1} ({\bf y} - {\boldsymbol \mu})
\]</span>
since <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is symmetric.</p>
<p>We can evaluate this for <span class="math inline">\(\mathbf{y}\)</span>, <span class="math inline">\(\boldsymbol{\mu}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span> as in Example <a href="matrix-based-computing.html#exm:mvn1">3.2</a> with the following</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="numerical-calculus.html#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> y <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">7</span>, <span class="fl">1.3</span>, <span class="fl">2.6</span>)</span>
<span id="cb282-2"><a href="numerical-calculus.html#cb282-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> mu <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb282-3"><a href="numerical-calculus.html#cb282-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> Sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb282-4"><a href="numerical-calculus.html#cb282-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> deriv1 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">solve</span>(Sigma, y <span class="sc">-</span> mu)</span></code></pre></div>
<p>which gives</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="numerical-calculus.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">as.vector</span>(deriv1)</span></code></pre></div>
<pre><code>## [1] -0.08  0.38 -0.14</code></pre>
<p>To approximate the derivative by finite-differencing, it makes sense to write a multi-purpose function for finite differencing, which we’ll call <code>fd()</code>.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="numerical-calculus.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fd <span class="ot">&lt;-</span> <span class="cf">function</span>(x, f, <span class="at">delta =</span> <span class="fl">1e-6</span>, ...) {</span>
<span id="cb285-2"><a href="numerical-calculus.html#cb285-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="co"># Function to evaluate derivative by finite-differencing</span></span>
<span id="cb285-3"><a href="numerical-calculus.html#cb285-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="co"># x is a p-vector</span></span>
<span id="cb285-4"><a href="numerical-calculus.html#cb285-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="co"># fn is the function for which the derivative is being calculated</span></span>
<span id="cb285-5"><a href="numerical-calculus.html#cb285-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="co"># delta is the finite-differencing step, which defaults to 10^{-6}</span></span>
<span id="cb285-6"><a href="numerical-calculus.html#cb285-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="co"># returns a vector of length x</span></span>
<span id="cb285-7"><a href="numerical-calculus.html#cb285-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   f0 <span class="ot">&lt;-</span> <span class="fu">f</span>(x, ...)</span>
<span id="cb285-8"><a href="numerical-calculus.html#cb285-8" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   p <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb285-9"><a href="numerical-calculus.html#cb285-9" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   f1 <span class="ot">&lt;-</span> <span class="fu">numeric</span>(p)</span>
<span id="cb285-10"><a href="numerical-calculus.html#cb285-10" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>p) {</span>
<span id="cb285-11"><a href="numerical-calculus.html#cb285-11" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>     x1 <span class="ot">&lt;-</span> x</span>
<span id="cb285-12"><a href="numerical-calculus.html#cb285-12" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>     x1[i] <span class="ot">&lt;-</span> x[i] <span class="sc">+</span> delta</span>
<span id="cb285-13"><a href="numerical-calculus.html#cb285-13" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>     f1[i] <span class="ot">&lt;-</span> <span class="fu">f</span>(x1, ...)</span>
<span id="cb285-14"><a href="numerical-calculus.html#cb285-14" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   }</span>
<span id="cb285-15"><a href="numerical-calculus.html#cb285-15" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   (f1 <span class="sc">-</span> f0) <span class="sc">/</span> delta</span>
<span id="cb285-16"><a href="numerical-calculus.html#cb285-16" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span></code></pre></div>
<p>Then we can use this with <code>dmvn3()</code> with the following</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="numerical-calculus.html#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> deriv2 <span class="ot">&lt;-</span> <span class="fu">fd</span>(y, dmvn3, <span class="at">mu =</span> mu, <span class="at">Sigma =</span> Sigma)</span></code></pre></div>
<p>which gives</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="numerical-calculus.html#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> deriv2</span></code></pre></div>
<pre><code>## [1] -0.0800002  0.3799993 -0.1400008</code></pre>
<p>and is the same as the analytical result</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="numerical-calculus.html#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">all.equal</span>(deriv1, deriv2)</span></code></pre></div>
<pre><code>## [1] &quot;Mean relative difference: 2.832689e-06&quot;</code></pre>
<p>once we allow for error in the finite-difference approximation.</p>
<!-- ### symbolic -->
<!-- probably skip -->
</div>
</div>
<div id="quadrature" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Quadrature<a href="numerical-calculus.html#quadrature" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another common requirement in statistics that some integral needs to be evaluated. To start, let’s consider a simple integral of the form
<span class="math display">\[
I = \int_a^b f(x) \text{d}x.
\]</span></p>
<p>We’ll first take a look at some <em>deterministic</em> approaches to numerically evaluating integrals. In fact, these all boil down to assuming that
<span class="math display">\[
I \simeq \sum_{i=1}^N w_i f(x_i^*)
\]</span>
for some weights <span class="math inline">\(w_i\)</span> and nodes <span class="math inline">\(x_i^*\)</span>, <span class="math inline">\(i = 1, \ldots, N\)</span>. Note that here we’re considering the so-called <em>composite</em> approach to approximating an interval, i.e. in which a rule is applied over a collection of sub-intervals.</p>
<div class="definition">
<p><span id="def:unlabeled-div-70" class="definition"><strong>Definition 4.4  (Relative absolute error) </strong></span>The <strong>relative absolute error</strong>, or sometimes just <em>relative error</em>, of an estimate of some true value is given by
<span class="math display">\[
\left\vert \dfrac{\text{true value} - \text{estimate}}{\text{true value}} \right\vert.
\]</span></p>
</div>
<div id="midpoint-rule" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Midpoint rule<a href="numerical-calculus.html#midpoint-rule" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Perhaps the first numerical integration scheme we come across is the mid point rule. Put simply, we divide <span class="math inline">\([a, b]\)</span> into <span class="math inline">\(N\)</span> equally-sized intervals, and use the midpoints of these as the nodes, <span class="math inline">\(x_i^*\)</span>. This gives</p>
<p><span class="math display">\[
\int_a^b f(x) \text{d}x \simeq h \sum_{i = 1}^N f(x_i^*),
\]</span></p>
<p>where <span class="math inline">\(x_i^* = a + (i - 0.5)(b - a)/N\)</span> and <span class="math inline">\(h = (b - a) / N\)</span>. The error in the approximation is <span class="math inline">\(O(h^2)\)</span>. Thus more intervals reduces <span class="math inline">\(h\)</span> and gives a more accurate approximation.</p>
<div class="example">
<p><span id="exm:midpoint" class="example"><strong>Example 4.5  (Midpoint rule) </strong></span>Consider the integral <span class="math inline">\(\int_0^1 \exp(x) \text{d}x = \exp(1) - 1 \simeq 1.7182818\)</span>. Use <code>R</code> and the midpoint rule to estimate the integral with <span class="math inline">\(N = 10\)</span>, <span class="math inline">\(100\)</span> and <span class="math inline">\(1000\)</span>. Then compare the relative absolute error of each.</p>
</div>
<p>We’ll start by calculating the true value of the integral, which we’ll stored as <code>true</code>.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="numerical-calculus.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> true <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span></span></code></pre></div>
<p>Then we’ll store the values of <span class="math inline">\(N\)</span> that we’re testing as <code>N_vals</code>.</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="numerical-calculus.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N_vals <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span></code></pre></div>
<p>The following then creates a vector, <code>midpoint</code>, in which to store the integral approximations, and calculates the approximations with a <code>for</code> loop. Inside the loop the integration nodes (i.e. the midpoints) and <span class="math inline">\(h\)</span> are calculated.</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="numerical-calculus.html#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> midpoint <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="fu">length</span>(N_vals))</span>
<span id="cb293-2"><a href="numerical-calculus.html#cb293-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(N_vals)) {</span>
<span id="cb293-3"><a href="numerical-calculus.html#cb293-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   N <span class="ot">&lt;-</span> N_vals[i]</span>
<span id="cb293-4"><a href="numerical-calculus.html#cb293-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   nodes <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span>N <span class="sc">-</span> .<span class="dv">5</span>) <span class="sc">/</span> N</span>
<span id="cb293-5"><a href="numerical-calculus.html#cb293-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   h <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> N</span>
<span id="cb293-6"><a href="numerical-calculus.html#cb293-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   midpoint[i] <span class="ot">&lt;-</span> h <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">exp</span>(nodes))</span>
<span id="cb293-7"><a href="numerical-calculus.html#cb293-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span>
<span id="cb293-8"><a href="numerical-calculus.html#cb293-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> midpoint</span></code></pre></div>
<pre><code>## [1] 1.717566 1.718275 1.718282</code></pre>
<p>The relative absolute error for each is then given in the vector <code>rel_err_mp</code> below.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="numerical-calculus.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err_mp <span class="ot">&lt;-</span> <span class="fu">abs</span>((true <span class="sc">-</span> midpoint) <span class="sc">/</span> true)</span>
<span id="cb295-2"><a href="numerical-calculus.html#cb295-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err_mp</span></code></pre></div>
<pre><code>## [1] 4.165452e-04 4.166655e-06 4.166667e-08</code></pre>
<p>We clearly see that the absolute error reduces by two factors of ten for each factor of ten increase in <span class="math inline">\(N\)</span>, which is consistent with the above comment of <span class="math inline">\(O(h^2)\)</span> error, where here <span class="math inline">\(h = 1/N\)</span>.</p>
</div>
<div id="simpsons-rule" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Simpson’s rule<a href="numerical-calculus.html#simpsons-rule" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The midpoint rule works simply by approximating <span class="math inline">\(f(x)\)</span> over a sub-interval of <span class="math inline">\([a, b]\)</span> by a horizontal line. The trapezium rule (which we’ll overlook) assumes a straight line. Simpson’s rule is derived from a quadratic approximation and given by</p>
<p><span class="math display" id="eq:simpson">\[\begin{equation}
\int_a^b f(x) \text{d}x \simeq \dfrac{h}{6} \left(f(a) + 4 \sum_{i = 1}^N f(x_{1i}^*) + 2\sum_{i = 1}^{N - 1} f(x_{2i}^*) + f(b)\right),
\tag{4.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(x_{1i}^* = a + h(2i - 1) / 2\)</span>, <span class="math inline">\(x_{2i}^* = a + ih\)</span> and <span class="math inline">\(h = (b - a)/N\)</span>. Note that Simpson’s rule requires <span class="math inline">\(N + 1\)</span> more evaluations of <span class="math inline">\(f\)</span> than the midpoint rule; however, a benefit of those extra evaluations is that its error reduces to <span class="math inline">\(O(h^4)\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-71" class="example"><strong>Example 4.6  (Simpson's rule) </strong></span>Now use <code>R</code> and Simpson’s rule to approximate the integral <span class="math inline">\(\int_0^1 \exp(x) \text{d}x = \exp(1) - 1\)</span> with <span class="math inline">\(N = 10\)</span>, <span class="math inline">\(100\)</span> and <span class="math inline">\(1000\)</span>, compare the relative absolute error for each, and against those of the midpoint rule in Example <a href="numerical-calculus.html#exm:midpoint">4.5</a>.</p>
</div>
<p>We already have <code>true</code> and <code>N_vals</code> from Example <a href="numerical-calculus.html#exm:midpoint">4.5</a>, and we can use a similar <code>for</code> loop to approximate the integral using Simpson’s rule. The main difference is that we create two sets of nodes, <code>nodes1</code> and <code>nodes2</code>, which correspond to the <span class="math inline">\(x_{1i}\)</span>s and <span class="math inline">\(x_{2i}\)</span>s in Equation <a href="numerical-calculus.html#eq:simpson">(4.1)</a>, respectively. The integral approximations are stored as <code>simpson</code></p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="numerical-calculus.html#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> simpson <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="fu">length</span>(N_vals))</span>
<span id="cb297-2"><a href="numerical-calculus.html#cb297-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N_vals <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb297-3"><a href="numerical-calculus.html#cb297-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(N_vals)) {</span>
<span id="cb297-4"><a href="numerical-calculus.html#cb297-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   N <span class="ot">&lt;-</span> N_vals[i]</span>
<span id="cb297-5"><a href="numerical-calculus.html#cb297-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   h <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> N</span>
<span id="cb297-6"><a href="numerical-calculus.html#cb297-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   simpson[i] <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">1</span>)</span>
<span id="cb297-7"><a href="numerical-calculus.html#cb297-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   nodes1 <span class="ot">&lt;-</span> h <span class="sc">*</span> (<span class="dv">2</span><span class="sc">*</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>N) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb297-8"><a href="numerical-calculus.html#cb297-8" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   simpson[i] <span class="ot">&lt;-</span> simpson[i] <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">exp</span>(nodes1))</span>
<span id="cb297-9"><a href="numerical-calculus.html#cb297-9" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   nodes2 <span class="ot">&lt;-</span> h <span class="sc">*</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>(N <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb297-10"><a href="numerical-calculus.html#cb297-10" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   simpson[i] <span class="ot">&lt;-</span> simpson[i] <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">exp</span>(nodes2))</span>
<span id="cb297-11"><a href="numerical-calculus.html#cb297-11" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   simpson[i] <span class="ot">&lt;-</span> h <span class="sc">*</span> simpson[i] <span class="sc">/</span> <span class="dv">6</span></span>
<span id="cb297-12"><a href="numerical-calculus.html#cb297-12" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span>
<span id="cb297-13"><a href="numerical-calculus.html#cb297-13" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">print</span>(simpson, <span class="at">digits =</span> <span class="dv">12</span>)</span></code></pre></div>
<pre><code>## [1] 1.71828188810 1.71828182847 1.71828182846</code></pre>
<p>and we print this to 11 decimal places so we can see where the approximations changes with <span class="math inline">\(N\)</span>. Finally we calculate the relative absolute errors, <code>rel_err_simp</code>,</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="numerical-calculus.html#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err_simp <span class="ot">&lt;-</span> <span class="fu">abs</span>((true <span class="sc">-</span> simpson) <span class="sc">/</span> true)</span>
<span id="cb299-2"><a href="numerical-calculus.html#cb299-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err_simp</span></code></pre></div>
<pre><code>## [1] 3.471189e-08 3.472270e-12 6.461239e-16</code></pre>
<p>and we see a dramatic improvement in the accuracy of approximation that Simpson’s rule brings, with relative absolute errors of the same order of magnitude as those form the midpoint rule using <span class="math inline">\(N = 1000\)</span> achieved with <span class="math inline">\(N=10\)</span> for Simpson’s rule. Note, though, that for given <span class="math inline">\(N\)</span>, Simpson’s rule requires <span class="math inline">\(N + 1\)</span> more evaluations of <span class="math inline">\(f()\)</span>.</p>
</div>
<div id="gaussian-quadrature" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Gaussian quadrature<a href="numerical-calculus.html#gaussian-quadrature" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ve seen that Simpson’s rule can considerably improve on the midpoint rule for approximating integrals. However, we might still consider both restrictive in that they consider an equally-spaced set of nodes.</p>
<div class="definition">
<p><span id="def:unlabeled-div-72" class="definition"><strong>Definition 4.5  (Gauss-Legendre quadrature rule) </strong></span>Consider <span class="math inline">\(g(x)\)</span>, a polynomial of degree <span class="math inline">\(2N - 1\)</span>, and a fixed weight function <span class="math inline">\(w(x)\)</span>. Then, the <strong>Gauss-Legendre quadrature rule</strong> states that <span class="math display">\[\int_a^b w(x) g(x) \text{d}x = \sum_{i = 1}^N w_i g(x_i),\]</span> where, for <span class="math inline">\(i = 1, \ldots, N\)</span>, <span class="math inline">\(w_i\)</span> and <span class="math inline">\(x_i\)</span> depend on <span class="math inline">\(w(x)\)</span>, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, but not <span class="math inline">\(g(x)\)</span>.</p>
</div>
<p>The Gauss-Legendre quadrature rule is the motivation for <strong>Gaussian quadrature</strong>, whereby we assume that the integral we’re interested in can be well-approximated by a polynomial. This results in the approximation <span class="math display">\[\int_a^b f(x) \text{d}x \simeq \sum_{i = 1}^N w_i f(x_i)\]</span> for a fixed set of <span class="math inline">\(x\)</span> values, <span class="math inline">\(x_i\)</span> with corresponding weights <span class="math inline">\(w_i\)</span>, for <span class="math inline">\(i = 1, \ldots, N\)</span>. There are many rules for choosing the weights, <span class="math inline">\(w_i\)</span>, but (perhaps fortunately) we won’t go into them in detail in MTH3045. Instead, we’ll just consider the function <code>pracma::gaussLegrendre()</code> (for which you’ll need to install the <code>pracma</code> package), where <code>pracma::gaussLegrendre(N, a, b)</code> produces <code>N</code> nodes and corresponding weights on the interval <span class="math inline">\([\)</span><code>a</code>,<code>b</code><span class="math inline">\(]\)</span>, with <span class="math inline">\(N =\)</span> <code>N</code>, <span class="math inline">\(a =\)</span> <code>a</code> and <span class="math inline">\(b =\)</span> <code>b</code>. The following produces nodes and weights for <span class="math inline">\(N = 10\)</span> on <span class="math inline">\([0, 1]\)</span></p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="numerical-calculus.html#cb301-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gq <span class="ot">&lt;-</span> pracma<span class="sc">::</span><span class="fu">gaussLegendre</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb301-2"><a href="numerical-calculus.html#cb301-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gq</span></code></pre></div>
<pre><code>## $x
##  [1] 0.01304674 0.06746832 0.16029522 0.28330230 0.42556283 0.57443717
##  [7] 0.71669770 0.83970478 0.93253168 0.98695326
## 
## $w
##  [1] 0.03333567 0.07472567 0.10954318 0.13463336 0.14776211 0.14776211
##  [7] 0.13463336 0.10954318 0.07472567 0.03333567</code></pre>
<div class="figure"><span style="display:block;" id="fig:gq2"></span>
<img src="main_files/figure-html/gq2-1.png" alt="Node and weights for Gauss-Legendre quadrature with $N = 10$ for integral on [0, 1]." width="672" />
<p class="caption">
Figure 4.1: Node and weights for Gauss-Legendre quadrature with <span class="math inline">\(N = 10\)</span> for integral on [0, 1].
</p>
</div>
<p>which we can see in Figure <a href="numerical-calculus.html#fig:gq2">4.1</a>, and shows that nodes are spread further apart towards the middle of the <span class="math inline">\([0, 1]\)</span> range, but given more weight. Note that <code>pracma::gaussLegrendre()</code> is named so because it implements Gauss-Legendre quadrature, i.e. Gaussian quadrature with Legendre polynomials<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-73" class="example"><strong>Example 4.7  (Gaussian quadrature) </strong></span>Now use <code>R</code> and Gauss-Legendre quadrature to approximate the integral <span class="math inline">\(\int_0^1 \exp(x) \text{d}x\)</span> with <span class="math inline">\(N = 10\)</span>. Explore what value of <span class="math inline">\(N\)</span> gives a comparable estimate to that of the midpoint rule with <span class="math inline">\(N = 100\)</span> based on relative absolute error.</p>
</div>
<p>We can re-use <code>true</code> from Example <a href="numerical-calculus.html#exm:midpoint">4.5</a> and then we’ll consider <span class="math inline">\(N=10\)</span>, 4 and 3, which we’ll call <code>N_vals</code>, and store the resulting integral approximations in <code>gauss</code>.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="numerical-calculus.html#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">4</span>, <span class="dv">3</span>)</span>
<span id="cb303-2"><a href="numerical-calculus.html#cb303-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gauss <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="fu">length</span>(N_vals))</span>
<span id="cb303-3"><a href="numerical-calculus.html#cb303-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(N_vals)) {</span>
<span id="cb303-4"><a href="numerical-calculus.html#cb303-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   N <span class="ot">&lt;-</span> N_vals[i]</span>
<span id="cb303-5"><a href="numerical-calculus.html#cb303-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   xw <span class="ot">&lt;-</span> pracma<span class="sc">::</span><span class="fu">gaussLegendre</span>(N, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb303-6"><a href="numerical-calculus.html#cb303-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   gauss[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(xw<span class="sc">$</span>w <span class="sc">*</span> <span class="fu">exp</span>(xw<span class="sc">$</span>x))</span>
<span id="cb303-7"><a href="numerical-calculus.html#cb303-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span>
<span id="cb303-8"><a href="numerical-calculus.html#cb303-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gauss</span></code></pre></div>
<pre><code>## [1] 1.718282 1.718282 1.718281</code></pre>
<p>The relative absolute errors, <code>rel_err_gauss</code>,</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="numerical-calculus.html#cb305-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err_gauss <span class="ot">&lt;-</span> <span class="fu">abs</span>((true <span class="sc">-</span> gauss) <span class="sc">/</span> true)</span>
<span id="cb305-2"><a href="numerical-calculus.html#cb305-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err_gauss</span></code></pre></div>
<pre><code>## [1] 2.584496e-16 5.429651e-10 4.795992e-07</code></pre>
<p>show that, having considered <span class="math inline">\(N = 3, 4, 10\)</span>, choosing <span class="math inline">\(N = 3\)</span> for Gaussian quadrature gives closest relative absolute error to that of the midpoint rule with <span class="math inline">\(N = 100\)</span>, which really is quite impressive. It is important to note, though, that <span class="math inline">\(f(x) = \exp(x)\)</span> is a very smooth function. For wiggler functions, larger <span class="math inline">\(N\)</span> is likely to be needed, and improvements in performance, such as Gaussian quadrature over the midpoint rule, might be significantly less.</p>
<div class="example">
<p><span id="exm:gqpois" class="example"><strong>Example 4.8  (Poisson marginal approximation using Gaussian quadrature) </strong></span>Consider a single random variable <span class="math inline">\(Y \mid \lambda \sim \text{Poisson}(\lambda)\)</span>, where we can characterise our prior beliefs about <span class="math inline">\(\lambda\)</span> as <span class="math inline">\(\lambda \sim \text{N}(\mu, \sigma^2)\)</span>. Use Gaussian quadrature with <span class="math inline">\(N = 9\)</span> to estimate the marginal pdf of <span class="math inline">\(Y\)</span> if <span class="math inline">\(\mu = 10\)</span> and <span class="math inline">\(\sigma = 3\)</span>.</p>
</div>
<p>The marginal distribution of <span class="math inline">\(Y\)</span> is given by
<span class="math display">\[
f(y) = \int_{-\infty}^\infty f(y \mid \lambda) f(\lambda) \text{d}\lambda.
\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-74" class="remark"><em>Remark</em>. </span>The <em>three sigma rule</em> is a heuristic rule of thumb that 99.7% of values lie within three standard deviations of the mean.</p>
</div>
<p>Hence for the <span class="math inline">\(\text{N}(10, 3^2)\)</span> distribution we should expect 99.7% of values to lie within <span class="math inline">\(10 \pm 3 \times3\)</span>. Hence we’ll take this as our range for the Gaussian quadrature nodes.</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="numerical-calculus.html#cb307-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> mu <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb307-2"><a href="numerical-calculus.html#cb307-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> sigma <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb307-3"><a href="numerical-calculus.html#cb307-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N <span class="ot">&lt;-</span> <span class="dv">9</span>  <span class="co"># no. of nodes</span></span>
<span id="cb307-4"><a href="numerical-calculus.html#cb307-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xw <span class="ot">&lt;-</span> pracma<span class="sc">::</span><span class="fu">gaussLegendre</span>(</span>
<span id="cb307-5"><a href="numerical-calculus.html#cb307-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         N,</span>
<span id="cb307-6"><a href="numerical-calculus.html#cb307-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         mu <span class="sc">-</span> <span class="dv">3</span> <span class="sc">*</span> sigma, <span class="co"># left-hand end</span></span>
<span id="cb307-7"><a href="numerical-calculus.html#cb307-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         mu <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> sigma <span class="co"># right-hand end</span></span>
<span id="cb307-8"><a href="numerical-calculus.html#cb307-8" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> ) </span>
<span id="cb307-9"><a href="numerical-calculus.html#cb307-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xw</span></code></pre></div>
<pre><code>## $x
## [1]  1.286558  2.475720  4.479657  7.081719 10.000000 12.918281 15.520343
## [8] 17.524280 18.713442
## 
## $w
## [1] 0.7314695 1.6258334 2.3454963 2.8111237 2.9721542 2.8111237 2.3454963
## [8] 1.6258334 0.7314695</code></pre>
<p>which are stored as <code>xw$x</code> with corresponding weights <code>xw$w</code>, <span class="math inline">\(w_1, \ldots, w_N\)</span>.</p>
<p>Next we want a set of values at which to evaluate <span class="math inline">\(f(y)\)</span>, and for this we’ll choose <span class="math inline">\(0, 1, \ldots, 30\)</span>, which we can create in <code>R</code> with</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="numerical-calculus.html#cb309-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> y_vals <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span></span></code></pre></div>
<p>Then we can estimate <span class="math inline">\(f(y)\)</span> as
<span class="math display">\[
\hat f(y) \simeq \sum_{i = 1}^N w_i f(y \mid \lambda_i^*) f(\lambda_i^*).
\]</span>
The following code gives <span class="math inline">\(\hat f(y)\)</span> as <code>fhat</code> for <span class="math inline">\(y\)</span> in the set of values <code>y_vals</code>.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="numerical-calculus.html#cb310-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> m <span class="ot">&lt;-</span> <span class="fu">length</span>(y_vals)</span>
<span id="cb310-2"><a href="numerical-calculus.html#cb310-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fhat <span class="ot">&lt;-</span> <span class="fu">numeric</span>(m)</span>
<span id="cb310-3"><a href="numerical-calculus.html#cb310-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>m) {</span>
<span id="cb310-4"><a href="numerical-calculus.html#cb310-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   fhat[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(xw<span class="sc">$</span>w <span class="sc">*</span> <span class="fu">dpois</span>(y_vals[i], xw<span class="sc">$</span>x) <span class="sc">*</span> </span>
<span id="cb310-5"><a href="numerical-calculus.html#cb310-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>                    <span class="fu">dnorm</span>(xw<span class="sc">$</span>x, mu, sigma))</span>
<span id="cb310-6"><a href="numerical-calculus.html#cb310-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span></code></pre></div>
<p>Finally, we’ll plot <span class="math inline">\(\hat f(y)\)</span> against the pdf of the Poisson(<span class="math inline">\(10\)</span>) distribution</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="numerical-calculus.html#cb311-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">matplot</span>(y_vals, <span class="fu">cbind</span>(fhat, <span class="fu">dpois</span>(y_vals, mu)), <span class="at">lwd =</span> <span class="dv">1</span>, </span>
<span id="cb311-2"><a href="numerical-calculus.html#cb311-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;y&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;f(y)&#39;</span>)</span>
<span id="cb311-3"><a href="numerical-calculus.html#cb311-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, <span class="fu">c</span>(<span class="st">&quot;f(y)&quot;</span>, <span class="st">&quot;f(y | 10)&quot;</span>),</span>
<span id="cb311-4"><a href="numerical-calculus.html#cb311-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>        <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="main_files/figure-html/gqpois5-1.png" width="672" /></p>
<p>which demonstrates that <span class="math inline">\(f(y)\)</span> is broader than <span class="math inline">\(f(y \mid 10)\)</span>, which is to be expected given that <span class="math inline">\(f(y)\)</span> integrates out the variability in <span class="math inline">\(\lambda\)</span> given by the <span class="math inline">\(\text{N}(10, 3^2)\)</span> distribution.</p>
</div>
<div id="one-dimensional-numerical-integration-in-r" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> One-dimensional numerical integration in <code>R</code><a href="numerical-calculus.html#one-dimensional-numerical-integration-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Unsurprisingly, <code>R</code> has a function for one-dimensional numerical integration. It’s called <code>integrate()</code>. It uses a method that builds on Gaussian quadrature, but we won’t go into its details. Use of <code>integrate()</code>, however, is fairly straightforward.</p>
<div class="example">
<p><span id="exm:unlabeled-div-75" class="example"><strong>Example 4.9  (Integration with integrate()) </strong></span>Evaluate the integral <span class="math inline">\(\int_0^1 \exp(x) \text{d}x = \exp(1) - 1\)</span> using <code>R</code>’s <code>integrate()</code> function with <span class="math inline">\(N = 10\)</span> and report its relative absolute error.</p>
</div>
<p>We can use the following code, where the first argument to <code>integrate()</code> is the function we’re integrating, the second and third are the lower and upper ranges of the definite integral, and <code>subdivisions</code> is the maximum number of nodes to use in the approximation, which defaults to 100.</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="numerical-calculus.html#cb312-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> true <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb312-2"><a href="numerical-calculus.html#cb312-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> estimate <span class="ot">&lt;-</span> <span class="fu">integrate</span>(<span class="cf">function</span>(x) <span class="fu">exp</span>(x), <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">subdivisions =</span> <span class="dv">10</span>)</span>
<span id="cb312-3"><a href="numerical-calculus.html#cb312-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err <span class="ot">&lt;-</span> <span class="fu">abs</span>(true <span class="sc">-</span> estimate<span class="sc">$</span>value) <span class="sc">/</span> true</span></code></pre></div>
<p>Note above that the absolute error is similarly tiny to that of Gaussian quadrature above. The values themselves, being so close to the machine tolerance, are incomparable. But we can be sure that the approximation is incredibly accurate.</p>
</div>
<div id="multi-dimensional-quadrature" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Multi-dimensional quadrature<a href="numerical-calculus.html#multi-dimensional-quadrature" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now suppose that we want to integrate a multi-variable function over some finite range. For simplicity, we’ll just consider the case of function of two variables, <span class="math inline">\(f(x, y)\)</span>. Then, by the earlier one-dimensional Gaussian quadrature we have that
<span class="math display">\[
\int f(x, y_j) \text{d} x \simeq \sum_{i = 1}^M w_{x,i} f(x_i, y_j)
\]</span>
from which it follows, by another application of Gaussian quadrature, that
<span class="math display">\[
\int \int f(x, y) \text{d} x \text{d} y \simeq \sum_{i=1}^{M} w_{x,i} \sum_{j=1}^N w_{y,j} f(x_i, y_j).
\]</span>
Note that the weight sequences <span class="math inline">\(w_{x, i}\)</span>, <span class="math inline">\(i = 1, \ldots, M\)</span>, and <span class="math inline">\(w_{y, j}\)</span>, <span class="math inline">\(j = 1, \ldots, N\)</span>, can be specified separately, i.e. according to different quadrature rules.</p>
<p>More generally, we therefore have that <span class="math display">\[
\int \ldots \int f(x_1, \ldots, x_d) \text{d} x_1 \ldots, \text{d} x_d = \int f(\mathbf{x}) \text{d} \mathbf{x} \simeq \sum_{i_1=1}^{N_1} \ldots \sum_{i_d=1}^{N_d} w_{x_1,i_1} \ldots w_{x_d, i_d} f(x_{1, i_1}, \ldots, x_{d, i_d}).
\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-76" class="remark"><em>Remark</em>. </span>In practice, multi-dimensional quadrature is only feasible for small numbers of dimensions. For example, consider a <span class="math inline">\(d\)</span>-variable function <span class="math inline">\(f\)</span>, such that each dimension has <span class="math inline">\(N\)</span> nodes. This will require <span class="math inline">\(N^d\)</span> evaluations of <span class="math inline">\(f\)</span>. Some useful numbers to draw upon are <span class="math inline">\(10^6\)</span>, and <span class="math inline">\(3^{15} \simeq 14348907\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:twovar" class="example"><strong>Example 4.10  (Two-variable numerical integration using the midpoint rule) </strong></span>Use the midpoint rule to approximate
<span class="math display">\[
I = \int_0^1 \int_0^1 \exp(x_1 + x_2) \text{d}x_1 \text{d}x_2
\]</span>
with 10 nodes for each variable, and estimate its relative absolute error.</p>
</div>
<p>The following sets <span class="math inline">\(d\)</span> and finds the integral’s true value, <code>true</code>.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="numerical-calculus.html#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> d <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb313-2"><a href="numerical-calculus.html#cb313-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> true <span class="ot">&lt;-</span> (<span class="fu">exp</span>(<span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">^</span>d</span></code></pre></div>
<p>We want <span class="math inline">\(N = 10\)</span> nodes per variable</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="numerical-calculus.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N <span class="ot">&lt;-</span> <span class="dv">10</span></span></code></pre></div>
<p>and then we’ll use the following nodes for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> on <span class="math inline">\([0, 1]\)</span></p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="numerical-calculus.html#cb315-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x1 <span class="ot">&lt;-</span> x2 <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span>N <span class="sc">-</span> .<span class="dv">5</span>) <span class="sc">/</span> N</span></code></pre></div>
<p>The approximation to the integral is given by
<span class="math display">\[
\hat I = \sum_{i = 1}^N\sum_{j = 1}^N w_{ij}f(x_{1i}, x_{2j})
\]</span>
where <span class="math inline">\(w_{ij} = N^{-d}\)</span> for <span class="math inline">\(i, j = 1, \ldots, N\)</span>. This can can be evaluated in <code>R</code> with</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="numerical-calculus.html#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> midpoint <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb316-2"><a href="numerical-calculus.html#cb316-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> w <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>(N<span class="sc">^</span>d)</span>
<span id="cb316-3"><a href="numerical-calculus.html#cb316-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N)</span>
<span id="cb316-4"><a href="numerical-calculus.html#cb316-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   midpoint <span class="ot">&lt;-</span> midpoint <span class="sc">+</span> w <span class="sc">*</span> <span class="fu">exp</span>(x1[i] <span class="sc">+</span> x2[j])</span></code></pre></div>
<p>where <code>midpoint</code> calculates <span class="math inline">\(\hat I\)</span> above. The following give the true integral, alongside its midpoint-rule based estimate, and the absolute relative error of the estimate, <code>rel.err</code></p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="numerical-calculus.html#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">c</span>(<span class="at">true =</span> true, <span class="at">midpoint =</span> midpoint, <span class="at">rel.err =</span> <span class="fu">abs</span>(midpoint <span class="sc">-</span> true) <span class="sc">/</span> true)</span></code></pre></div>
<pre><code>##         true     midpoint      rel.err 
## 2.9524924420 2.9500332614 0.0008329168</code></pre>
<p>We see that the estimate is reasonably accurate, but we have had to evaluate <span class="math inline">\(f(x_1, x_2)\)</span> 100 times.</p>
<div class="example">
<p><span id="exm:twovargq" class="example"><strong>Example 4.11  (Two-variable numerical integration using Gaussian quadrature) </strong></span>Use Gaussian quadrature to approximate <span class="math inline">\(I\)</span> from Example <a href="numerical-calculus.html#exm:twovar">4.10</a> with 4 nodes for each variable, and estimate its relative absolute error.</p>
</div>
<p>We can take <code>d</code> and <code>true</code> from Example <a href="numerical-calculus.html#exm:twovar">4.10</a>. Then we calculate <span class="math inline">\(\hat I\)</span> as above, but using the integration nodes and weights of Gaussian quadrature.</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="numerical-calculus.html#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb319-2"><a href="numerical-calculus.html#cb319-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xw1 <span class="ot">&lt;-</span> xw2 <span class="ot">&lt;-</span> pracma<span class="sc">::</span><span class="fu">gaussLegendre</span>(N, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb319-3"><a href="numerical-calculus.html#cb319-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gq <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb319-4"><a href="numerical-calculus.html#cb319-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N)</span>
<span id="cb319-5"><a href="numerical-calculus.html#cb319-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   gq <span class="ot">&lt;-</span> gq <span class="sc">+</span> xw1<span class="sc">$</span>w[i] <span class="sc">*</span> xw2<span class="sc">$</span>w[j] <span class="sc">*</span> <span class="fu">exp</span>(xw1<span class="sc">$</span>x[i] <span class="sc">+</span> xw2<span class="sc">$</span>x[j])</span>
<span id="cb319-6"><a href="numerical-calculus.html#cb319-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gq</span></code></pre></div>
<pre><code>## [1] 2.952492</code></pre>
<p>We again see below that Gaussian quadrature gives an incredibly accurate estimate</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="numerical-calculus.html#cb321-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">c</span>(<span class="at">true =</span> true, <span class="at">guass_quad =</span> gq, <span class="at">rel.err =</span> <span class="fu">abs</span>(gq <span class="sc">-</span> true) <span class="sc">/</span> true)</span></code></pre></div>
<pre><code>##         true   guass_quad      rel.err 
## 2.952492e+00 2.952492e+00 1.085930e-09</code></pre>
<p>yet now we’ve only had to evaluate <span class="math inline">\(f(x_1, x_2)\)</span> 16 times.</p>
<div class="example">
<p><span id="exm:fivevar" class="example"><strong>Example 4.12  (Five-variable numerical integration using Gaussian quadrature) </strong></span>Use the Gaussian quadrature to approximate
<span class="math display">\[
I = \int_0^1 \ldots \int_0^1 \exp(\sum_{i = 1}^5 x_i) \text{d}x_1 \ldots \text{d}x_5
\]</span>
with 4 nodes for each variable, and estimate its relative absolute error.</p>
</div>
<p>We can proceed as in Example <a href="numerical-calculus.html#exm:twovargq">4.11</a> by storing <span class="math inline">\(d\)</span> as <code>d</code> and <span class="math inline">\(I\)</span> as <code>true</code>.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="numerical-calculus.html#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> d <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb323-2"><a href="numerical-calculus.html#cb323-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> true <span class="ot">&lt;-</span> (<span class="fu">exp</span>(<span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">^</span>d</span></code></pre></div>
<p>Now we’ll need a new tactic, because forming <code>xw1</code>, <code>xw2</code>, …, <code>xw5</code> will be rather laborious. Having the same nodes and weights for each variable, i.e. for <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, , <span class="math inline">\(x_5\)</span>, simplifies the following code a bit. We’ll start by setting <span class="math inline">\(n\)</span> and getting the quadrature nodes and weights, which will be repeated for each variable.</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="numerical-calculus.html#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb324-2"><a href="numerical-calculus.html#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xw <span class="ot">&lt;-</span> pracma<span class="sc">::</span><span class="fu">gaussLegendre</span>(N, <span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>Then we want to put together all the combinations of the nodes, <code>X</code>, and weights, <code>W</code>, that will be used.</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="numerical-calculus.html#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xxww <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span>d, <span class="cf">function</span>(i) xw)</span>
<span id="cb325-2"><a href="numerical-calculus.html#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> X <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="fu">lapply</span>(xxww, <span class="st">&#39;[[&#39;</span>, <span class="dv">1</span>))</span>
<span id="cb325-3"><a href="numerical-calculus.html#cb325-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> W <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="fu">lapply</span>(xxww, <span class="st">&#39;[[&#39;</span>, <span class="dv">2</span>))</span></code></pre></div>
<p>We then want multiply all the combinations of weights, for which would could use <code>apply(..., 1, prod)</code>, but instead we can use <code>rowSums()</code> in the following way</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="numerical-calculus.html#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> w <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rowSums</span>(<span class="fu">log</span>(W)))</span></code></pre></div>
<p>We then calculate <span class="math inline">\(\hat I\)</span> and store this as <code>gq</code></p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="numerical-calculus.html#cb327-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> gq <span class="ot">&lt;-</span> <span class="fu">sum</span>(w <span class="sc">*</span> <span class="fu">exp</span>(<span class="fu">rowSums</span>(X)))</span></code></pre></div>
<p>and see that we still get an excellent approximation to <span class="math inline">\(I\)</span></p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="numerical-calculus.html#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">c</span>(<span class="at">true =</span> true, <span class="at">gauss_quad =</span> gq, <span class="at">rel.err =</span> <span class="fu">abs</span>(gq <span class="sc">-</span> true) <span class="sc">/</span> true)</span></code></pre></div>
<pre><code>##         true   gauss_quad      rel.err 
## 1.497863e+01 1.497863e+01 2.714825e-09</code></pre>
<p>but have now evaluated <span class="math inline">\(\exp(\sum_{j = 1}^5 x_i)\)</span> 1024 times.</p>
</div>
</div>
<div id="laplaces-method" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Laplace’s method<a href="numerical-calculus.html#laplaces-method" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="an-aside-on-taylor-series-in-one-dimension" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> An aside on Taylor series in one dimension<a href="numerical-calculus.html#an-aside-on-taylor-series-in-one-dimension" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In MTH1002 you met Taylor series expansions. The expansion is at the centre of many useful statistical approximations.</p>
<div class="theorem">
<p><span id="thm:taylor1" class="theorem"><strong>Theorem 4.1  (Taylor series in one dimension) </strong></span>Consider a function <span class="math inline">\(f(x)\)</span> in the region of a point <span class="math inline">\(x_0\)</span> that is infinitely differentiable. Then
<span class="math display">\[
f(x) = f(x_0) + \dfrac{f&#39;(x_0)}{1!}(x - x_0) + \dfrac{f&#39;&#39;(x_0)}{2!}(x - x_0)^2 + \dfrac{f^{(3)}(x_0)}{3!}(x - x_0)^3 + \ldots
\]</span>
where <span class="math inline">\(f&#39;(x)\)</span> and <span class="math inline">\(f&#39;&#39;(x)\)</span> denote the first and second derivatives of <span class="math inline">\(f(x)\)</span> w.r.t. <span class="math inline">\(x\)</span>, respectively, and <span class="math inline">\(f^{(n)}(x)\)</span> denotes the <span class="math inline">\(n\)</span>th derivative, for <span class="math inline">\(n = 3, 4, 5, \ldots\)</span>.</p>
</div>
<p>From a statistical perspective we’re often just looking to approximate <span class="math inline">\(f(x)\)</span> up to second-order terms, and hence we may work with the truncated expansion
<span class="math display" id="eq:taylor">\[\begin{equation}
f(x) \simeq f(x_0) + (x - x_0)f&#39;(x_0) + \dfrac{1}{2}(x - x_0)^2 f&#39;&#39;(x_0). \tag{4.2}
\end{equation}\]</span></p>
</div>
<div id="definition-1" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Definition<a href="numerical-calculus.html#definition-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-77" class="definition"><strong>Definition 4.6  (Laplace's method in one dimension) </strong></span>Consider the integral
<span class="math display" id="eq:In">\[\begin{equation}
I_n = \int_{-\infty}^{\infty} \text{e}^{-nf(x)} \text{d}x,
\tag{4.3}
\end{equation}\]</span>
where <span class="math inline">\(f(x)\)</span> is a <em>convex</em> function with a minimum at <span class="math inline">\(x = \tilde x\)</span>, so that <span class="math inline">\(f&#39;(\tilde x) = 0\)</span>. The integral can be approximated, using <strong>Laplace’s method</strong>, as
<span class="math display" id="eq:laplace">\[\begin{equation}
I_n \simeq \text{e}^{-n[f(\tilde x)]} \sqrt{\dfrac{2 \pi}{nf&#39;&#39;(\tilde x)}},
\tag{4.4}
\end{equation}\]</span>
which is also sometimes referred to as the <em>Laplace approximation</em><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-78" class="remark"><em>Remark</em>. </span>Laplace’s method can be derived from the truncated Taylor expansion of Equation <a href="numerical-calculus.html#eq:taylor">(4.2)</a>. If we expand <span class="math inline">\(f(x)\)</span> about its global maximum, which we’ll denote by <span class="math inline">\(\tilde x\)</span>, then
<span class="math display">\[
f(x) \simeq f(\tilde x) + \dfrac{1}{2}(x - \tilde x)^2 f&#39;&#39;(\tilde x),
\]</span>
since <span class="math inline">\(f&#39;(\tilde x) = 0\)</span>. Substituting this in we get
<span class="math display">\[\begin{align*} I_n
&amp;\simeq \int_{-\infty}^{\infty} \exp\left\{-n\left[f(\tilde x) + \dfrac{1}{2}(x - \tilde x)^2 f&#39;&#39;(\tilde x)\right]\right\} \text{d}x\\
&amp;= \text{e}^{-n[f(\tilde x)]} \int_{-\infty}^{\infty} \exp\left\{-\dfrac{n(x - \tilde x)^2 f&#39;&#39;(\tilde x)}{2}\right\} \text{d}x.
\end{align*}\]</span></p>
<p>We recognise <span class="math inline">\(-n(x - \tilde x)^2 f&#39;&#39;(\tilde x) / 2\)</span> as the exponential part of the Normal(<span class="math inline">\(\tilde x\)</span>, <span class="math inline">\(1/nf&#39;&#39;(\tilde x)\)</span>) distribution, for which the pdf, <span class="math inline">\(\sqrt{nf&#39;&#39;(\tilde x) / (2 \pi)} \exp\{- n(x - \tilde x)^2 f&#39;&#39;(\tilde x) / 2\}\)</span>, integrates to unity, and so
<span class="math display">\[
\int_{-\infty}^\infty \exp\left\{-\dfrac{n(x - \tilde x)^2 f&#39;&#39;(\tilde x) }{2} \right\} \text{d} x = \sqrt{\dfrac{2 \pi}{nf&#39;&#39;(\tilde x)}}.
\]</span>
Substituting this into <span class="math inline">\(I_n\)</span> above we get <span class="math inline">\(I_n \simeq \text{e}^{-n[f(\tilde x)]} \sqrt{(2 \pi) / nf&#39;&#39;(\tilde x)}\)</span>, as stated in Equation <a href="numerical-calculus.html#eq:laplace">(4.4)</a>.</p>
<p>Knowledge of the derivation of Laplace’s method is beyond the scope of MTH3045.</p>
</div>
<!-- \[  -->
<!-- I_n \simeq \text{e}^{n[f(\tilde x) \int_a^b \text{e}^{\dfrac{1}{2}(x - \tilde x)^2 f''(\tilde x)]} \text{d}x, -->
<!-- \]  -->
<!-- \begin{align*} -->
<!-- I_n &\simeq \text{e}^{-nf(x)h(\tilde u)} \int_{-\infty}^\infty \text{e}^{-n[h''(u - \tilde u)]^2} \text{d}u,\\ -->
<!-- &= \text{e}^{-nh(\tilde u)} \int_{-\infty}^\infty \text{e}^{-z^2 / 2} \dfrac{du}{dz} \text{d}u, \left(\text{substituting }z^2 = n[h''(u - \tilde u)]^2\right)\\ -->
<!-- &= \left(\dfrac{2 \pi}{n h''(\tilde u)}\right)^{1/2}\text{e}^{-nh(\tilde u)}, -->
<!-- \end{align*} -->
<!-- https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html -->
<div class="example">
<p><span id="exm:unlabeled-div-79" class="example"><strong>Example 4.13  (Poisson marginal approximation using Laplace's method) </strong></span>Recall Example <a href="numerical-calculus.html#exm:gqpois">4.8</a>. Use Laplace’s method to approximate <span class="math inline">\(f(y)\)</span>.</p>
</div>
<p>Given Equation <a href="numerical-calculus.html#eq:In">(4.3)</a> we have
<span class="math display">\[
f(y, \lambda) = \lambda - y \log(\lambda) + \dfrac{1}{2 \sigma^2}(\lambda - \mu)^2 + \text{constant},
\]</span>
with <span class="math inline">\(n = 1\)</span>, which is based on swapping <span class="math inline">\(x\)</span> for <span class="math inline">\(\lambda\)</span>. Then
<span class="math display">\[
f&#39;(y, \lambda) = 1 - \dfrac{y}{\lambda} + \dfrac{1}{\sigma^2}(\lambda - \mu)
\]</span>
and
<span class="math display">\[
f&#39;&#39;(y, \lambda) = \dfrac{y}{\lambda^2} + \dfrac{1}{\sigma^2}.
\]</span></p>
<p>We’ll first set <code>sigsq</code>.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="numerical-calculus.html#cb330-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> sigsq <span class="ot">&lt;-</span> sigma<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<p>We can’t find <span class="math inline">\(\tilde \lambda\)</span> analytically, and so we’ll find it numerically instead. The following function, <code>tilde_lambda(y, mu, sigsq)</code>, gives <span class="math inline">\(\tilde \lambda\)</span> given <span class="math inline">\(y =\)</span>, <code>y</code>, <span class="math inline">\(\mu =\)</span> <code>mu</code> and <span class="math inline">\(\sigma^2 =\)</span> <code>sigsq</code>.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="numerical-calculus.html#cb331-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f <span class="ot">&lt;-</span> <span class="cf">function</span>(lambda, y, mu, sigsq)</span>
<span id="cb331-2"><a href="numerical-calculus.html#cb331-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="sc">-</span> <span class="fu">dpois</span>(y, lambda, <span class="at">log =</span> <span class="cn">TRUE</span>) <span class="sc">-</span> <span class="fu">dnorm</span>(lambda, mu, <span class="fu">sqrt</span>(sigsq), <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb331-3"><a href="numerical-calculus.html#cb331-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tilde_lambda <span class="ot">&lt;-</span> <span class="cf">function</span>(y, mu, sigsq) {</span>
<span id="cb331-4"><a href="numerical-calculus.html#cb331-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="fu">optimize</span>(f, <span class="fu">c</span>(.<span class="dv">1</span>, <span class="dv">20</span>), <span class="at">y =</span> y, <span class="at">mu =</span> mu, <span class="at">sigsq =</span> sigsq)<span class="sc">$</span>minimum</span>
<span id="cb331-5"><a href="numerical-calculus.html#cb331-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span></code></pre></div>
<p>We’ll re-use <code>mu</code>, <code>sigsq</code> and <code>y_vals</code> from Example <a href="numerical-calculus.html#exm:gqpois">4.8</a>. We then want to find <span class="math inline">\(\tilde \lambda\)</span> for each <span class="math inline">\(y\)</span> in <code>y_vals</code>, which we’ll store as the vector <code>tilde_lambdas</code>.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="numerical-calculus.html#cb332-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tilde_lambdas <span class="ot">&lt;-</span> <span class="fu">sapply</span>(y_vals, tilde_lambda, <span class="at">mu =</span> mu, <span class="at">sigsq =</span> sigsq)</span>
<span id="cb332-2"><a href="numerical-calculus.html#cb332-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tilde_lambdas</span></code></pre></div>
<pre><code>##  [1]  1.000000  3.541378  4.771984  5.720154  6.520803  7.226814  7.865452
##  [8]  8.452984  8.999993  9.513868 10.000009 10.462438 10.904333 11.328202
## [15] 11.736102 12.129703 12.510409 12.879438 13.237752 13.586233 13.925720
## [22] 14.256831 14.580111 14.896197 15.205447 15.508331 15.805227 16.096470
## [29] 16.382372 16.663214 16.939295</code></pre>
<p>We then want to evaluate the approximation to <span class="math inline">\(I_n\)</span> given by Equation <a href="numerical-calculus.html#eq:laplace">(4.4)</a>. We’ll start with a function to evaluate <span class="math inline">\(f&#39;&#39;(\tilde \lambda)\)</span>, which we’ll use for each <span class="math inline">\(\tilde \lambda\)</span> in <code>tilde_lambdas</code>.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="numerical-calculus.html#cb334-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f2 <span class="ot">&lt;-</span> <span class="cf">function</span>(lambda, y, mu, sigsq)</span>
<span id="cb334-2"><a href="numerical-calculus.html#cb334-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   y <span class="sc">/</span> lambda<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span> <span class="sc">/</span> sigsq</span>
<span id="cb334-3"><a href="numerical-calculus.html#cb334-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f2_lambdas <span class="ot">&lt;-</span> <span class="fu">f2</span>(tilde_lambdas, y_vals, mu, sigsq)</span></code></pre></div>
<p>Then we’ll approximate <span class="math inline">\(I_n\)</span> and store this as <code>fhat2</code>.</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="numerical-calculus.html#cb335-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fhat2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> pi <span class="sc">/</span> f2_lambdas) <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fu">f</span>(tilde_lambdas, y_vals, mu, sigsq))</span></code></pre></div>
<p>Finally we’ll plot the Laplace approximation to <span class="math inline">\(f(y)\)</span> against <span class="math inline">\(y\)</span> for <code>y_vals</code>, i.e. <code>fhat2</code>, alongside the estimate obtained by Gaussian quadrature in Example <a href="numerical-calculus.html#exm:gqpois">4.8</a></p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="numerical-calculus.html#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">matplot</span>(y_vals, <span class="fu">cbind</span>(fhat, fhat2), </span>
<span id="cb336-2"><a href="numerical-calculus.html#cb336-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;y&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;f(y)&#39;</span>)</span>
<span id="cb336-3"><a href="numerical-calculus.html#cb336-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, <span class="fu">c</span>(<span class="st">&quot;Laplace&#39;s method&quot;</span>, <span class="st">&quot;Gaussian quadrature&quot;</span>),</span>
<span id="cb336-4"><a href="numerical-calculus.html#cb336-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>        <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="main_files/figure-html/lapois5-1.png" width="672" /></p>
<p>and see that the two approaches to approximate <span class="math inline">\(f(y)\)</span> give very similar results.</p>
</div>
<div id="laplaces-method-for-multiple-dimensions" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Laplace’s method for multiple dimensions<a href="numerical-calculus.html#laplaces-method-for-multiple-dimensions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Above we considered Taylor series for a function of one variable. Laplace’s method extends to higher dimensions, although the one-variable case will only be assessed in MTH3045.</p>
<p>Consider the Taylor series for functions of multiple variables, denote <span class="math inline">\(f(\mathbf{x})\)</span>, where <span class="math inline">\(f: \mathbb{R}^n \to \mathbb{R}\)</span>. The infinite series notation becomes a bit cumbersome, so we’ll skip to the second-order approximation.
<span class="math display">\[
f(\mathbf{x}) \simeq f(\mathbf{x}_0) + (\mathbf{x} - \mathbf{x}_0)^\text{T} \nabla f(\mathbf{x}_0) + \dfrac{1}{2} (\mathbf{x} - \mathbf{x}_0)^\text{T} \left[\nabla^2 f(\mathbf{x}_0)\right] (\mathbf{x} - \mathbf{x}_0).
\]</span></p>
<p>Then consider the integral
<span class="math display">\[
I_n = \int \text{e}^{-nf(\mathbf{x})} \text{d} \mathbf{x}.
\]</span></p>
<p>Laplace’s method gives that
<span class="math display">\[
I_n \simeq \left(\dfrac{2 \pi}{n}\right)^{d/2} \dfrac{\text{e}^{-nf(\tilde{\mathbf{x}})}}{|\mathbf{H}|^{1/2}},
\]</span>
where <span class="math inline">\(\mathbf{H}\)</span> is the Hessian matrix of <span class="math inline">\(f(\mathbf{x})\)</span> evaluated at <span class="math inline">\(\mathbf{x} = \tilde{\mathbf{x}}\)</span>, i.e. <span class="math inline">\(\nabla^2 f(\tilde{\mathbf{x}})\)</span>. The above approximation results from integrating out the <span class="math inline">\(MVN_p(\tilde{\mathbf{x}}, \mathbf{H}^{-1})\)</span> distribution. This is effectively a multivariate extension to integrating out the <span class="math inline">\(N(\tilde x, 1 / nf&#39;&#39;(\tilde x))\)</span>, which led to Equation <a href="numerical-calculus.html#eq:laplace">(4.4)</a>.</p>
</div>
</div>
<div id="monte-carlo-integration" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Monte Carlo integration<a href="numerical-calculus.html#monte-carlo-integration" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far we have considered <em>deterministic</em> approaches to numerical integration; these will always give the same answer. It is worth, however, considering a stochastic approach to integration known as <em>Monte Carlo</em> integration.</p>
<p>Now consider <span class="math inline">\(\mathbf{X} = (X_1, \ldots, X_d)\)</span> on some finite region <span class="math inline">\(\mathcal{X}\)</span> with volume <span class="math inline">\(V(\mathcal{X})\)</span>, where, additionally <span class="math inline">\(\mathbf{X}\)</span> is uniformly distributed on <span class="math inline">\(\mathcal{X}\)</span>. Then
<span class="math display" id="eq:mc">\[\begin{equation}
I_{\mathcal{X}} = \int_{\mathbf{x} \in \mathcal{X}} f(\mathbf{x}) \text{d} \mathbf{x} = \text{E}[f(\mathbf{X})] V(\mathcal{X}).
\tag{4.5}
\end{equation}\]</span>
The standard Monte Carlo estimate for <span class="math inline">\(I_{\mathcal{X}}\)</span> is given by
<span class="math display">\[
\hat{I}_{\mathcal{X}} \simeq \dfrac{V(\mathcal{X})}{N} \sum_{i = 1}^N f(\tilde{\mathbf{x}}_i)
\]</span>
where <span class="math inline">\(\tilde{\mathbf{x}}_i\)</span>, for <span class="math inline">\(i = 1, \ldots, N\)</span>, are drawn <em>uniformly</em> from <span class="math inline">\(\mathcal{X}\)</span>.</p>
<p>We can immediately see that Monte Carlo integration is a powerful tool as, provided we can uniformly generate points on <span class="math inline">\(\mathcal{X}\)</span>, <span class="math inline">\(\tilde{\mathbf{x}}\)</span>, and evaluate <span class="math inline">\(f(\tilde{\mathbf{x}})\)</span>, then we can approximate <span class="math inline">\(I\)</span>. A natural next question is the accuracy of this approximation and, as <span class="math inline">\(\hat{I}_{\mathcal{X}}\)</span> is unbiased its variance
<span class="math display">\[
\text{Var}(\hat{I}_{\mathcal{X}}) = \dfrac{V(\mathcal{X})^2}{N} \text{Var}[f(\mathbf{X})]
\]</span>
is key. As <span class="math inline">\(\text{Var}(\hat{I}_{\mathcal{X}})\)</span> decreases linearly with <span class="math inline">\(1/N\)</span>, convergence is rather slow. The following example confirms this.</p>
<div class="example">
<p><span id="exm:unlabeled-div-80" class="example"><strong>Example 4.14  (One-dimensional Monte Carlo integration) </strong></span>Recall the integral <span class="math inline">\(\int_0^1 \exp(x) \text{d}x = \exp(1) - 1 \simeq 1.7182818\)</span> from Example <a href="numerical-calculus.html#exm:midpoint">4.5</a>. Use <code>R</code> and Monte Carlo integration to approximate the integral with <span class="math inline">\(N = 100\)</span>, <span class="math inline">\(1000\)</span> and <span class="math inline">\(10000\)</span>, using the mean of <span class="math inline">\(m = 100\)</span> replicates for each value of <span class="math inline">\(N\)</span> as your approximation. Then compare the relative absolute error for each value of <span class="math inline">\(N\)</span>.</p>
</div>
<p>We’ll start with a function, <code>mc(f, N)</code>, which we’ll use to approximate the integral for given <span class="math inline">\(N\)</span></p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="numerical-calculus.html#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> mc <span class="ot">&lt;-</span> <span class="cf">function</span>(f, N, <span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>, ...) {</span>
<span id="cb337-2"><a href="numerical-calculus.html#cb337-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   x <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, a, b)</span>
<span id="cb337-3"><a href="numerical-calculus.html#cb337-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   V <span class="ot">&lt;-</span> b <span class="sc">-</span> a</span>
<span id="cb337-4"><a href="numerical-calculus.html#cb337-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   V <span class="sc">*</span> <span class="fu">mean</span>(<span class="fu">f</span>(x, ...))</span>
<span id="cb337-5"><a href="numerical-calculus.html#cb337-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span></code></pre></div>
<p>and will quickly test for <span class="math inline">\(N = 100\)</span></p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="numerical-calculus.html#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">mc</span>(<span class="cf">function</span>(x) <span class="fu">exp</span>(x), <span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 1.832858</code></pre>
<p>Note above that as the vector <code>x</code> contains random variable, you may get a slightly different result; hence the replicates.</p>
<p>Now we’ll perform <span class="math inline">\(m = 100\)</span> replicates for each Monte Carlo sample size <span class="math inline">\(N\)</span>.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="numerical-calculus.html#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> estimates <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">3</span>)</span>
<span id="cb340-2"><a href="numerical-calculus.html#cb340-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N_vals <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb340-3"><a href="numerical-calculus.html#cb340-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> m <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb340-4"><a href="numerical-calculus.html#cb340-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(N_vals))</span>
<span id="cb340-5"><a href="numerical-calculus.html#cb340-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   estimates[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">replicate</span>(m, <span class="fu">mc</span>(<span class="cf">function</span>(x) <span class="fu">exp</span>(x), N_vals[i])))</span>
<span id="cb340-6"><a href="numerical-calculus.html#cb340-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> estimates</span></code></pre></div>
<pre><code>## [1] 1.715251 1.719208 1.718545</code></pre>
<p>Finally, we’ll compare these to the true integral, <code>true</code> below, by calculating the relative absolute error, <code>rel_err</code></p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="numerical-calculus.html#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> true <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb342-2"><a href="numerical-calculus.html#cb342-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err <span class="ot">&lt;-</span> <span class="fu">abs</span>(true <span class="sc">-</span> estimates) <span class="sc">/</span> true</span>
<span id="cb342-3"><a href="numerical-calculus.html#cb342-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rel_err</span></code></pre></div>
<pre><code>## [1] 0.0017637093 0.0005390542 0.0001529152</code></pre>
<p>and see that the higher values of <span class="math inline">\(N\)</span> give more accurate approximations, once we allow for variability in Monte Carlo samples.</p>
<div class="example">
<p><span id="exm:unlabeled-div-81" class="example"><strong>Example 4.15  (Multi-dimensional Monte Carlo integration) </strong></span>Recall Example <a href="numerical-calculus.html#exm:fivevar">4.12</a>, i.e.
<span class="math display">\[
I = \int_0^1 \ldots \int_0^1 \exp(\sum_{i = 1}^5 x_i) \text{d}x_1 \ldots \text{d}x_5.
\]</span>
Use Monte Carlo integration with Monte Carlo samples of size <span class="math inline">\(N = 10, 100, 10^3, 10^4\)</span> and <span class="math inline">\(10^5\)</span> to estimate <span class="math inline">\(I\)</span> and estimate the relative absolute error for each <span class="math inline">\(N\)</span>.</p>
</div>
<p>The following code approximates the integral for the different values of <span class="math inline">\(N\)</span>.</p>
<pre><code>##          true monte_carlo     rel.err
## [1,] 14.97863    17.62581 0.176730779
## [2,] 14.97863    13.99063 0.065960649
## [3,] 14.97863    14.91521 0.004233631
## [4,] 14.97863    14.92255 0.003743597
## [5,] 14.97863    15.00143 0.001522209</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="numerical-calculus.html#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> d <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb345-2"><a href="numerical-calculus.html#cb345-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> true <span class="ot">&lt;-</span> (<span class="fu">exp</span>(<span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">^</span>d</span>
<span id="cb345-3"><a href="numerical-calculus.html#cb345-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> NN <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb345-4"><a href="numerical-calculus.html#cb345-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> f <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="fu">length</span>(NN))</span>
<span id="cb345-5"><a href="numerical-calculus.html#cb345-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(NN))</span>
<span id="cb345-6"><a href="numerical-calculus.html#cb345-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   f[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">exp</span>(<span class="fu">rowSums</span>(<span class="fu">matrix</span>(<span class="fu">runif</span>(d <span class="sc">*</span> NN[i]), NN[i]))))</span>
<span id="cb345-7"><a href="numerical-calculus.html#cb345-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">cbind</span>(<span class="at">true =</span> true, <span class="at">monte_carlo =</span> f, <span class="at">rel.err =</span> <span class="fu">abs</span>(f <span class="sc">-</span> true) <span class="sc">/</span> true)</span></code></pre></div>
<p>We see that the relative absolute error decreases as <span class="math inline">\(N\)</span> increases, even with just one replicate.</p>
<p>The above integral, <span class="math inline">\(I_{\mathcal{X}}\)</span> in Equation <a href="numerical-calculus.html#eq:mc">(4.5)</a>, can be seen as a special case of
<span class="math display">\[
I_{g(\mathcal{X})} = \int_{\mathbf{x} \in \mathcal{X}} f(\mathbf{x}) g(\mathbf{x}) \text{d} \mathbf{x},
\]</span>
for a pdf <span class="math inline">\(g(\mathbf{x})\)</span>, which can be estimated by Monte Carlo as
<span class="math display" id="eq:gmc">\[\begin{equation}
\hat{I}_{g(\mathcal{X})} \simeq \dfrac{1}{N} \sum_{i = 1}^N f(\tilde{\mathbf{x}}_i),
\tag{4.6}
\end{equation}\]</span>
where <span class="math inline">\(\tilde{\mathbf{x}}_i\)</span> are draws from the pdf <span class="math inline">\(g(\mathbf{x})\)</span>.</p>
<div class="example">
<p><span id="exm:mcpois" class="example"><strong>Example 4.16  (Poisson marginal approximation using Monte Carlo integration) </strong></span>Recall Example <a href="numerical-calculus.html#exm:gqpois">4.8</a>. Use Monte Carlo integration with <span class="math inline">\(N = 1000\)</span> to approximate <span class="math inline">\(f(y)\)</span>.</p>
</div>
<p>We need to draw a sample of size <span class="math inline">\(N = 1000\)</span> from <span class="math inline">\(f(\lambda)\)</span>, which corresponds to <span class="math inline">\(g(\mathbf{x})\)</span> in Equation <a href="numerical-calculus.html#eq:gmc">(4.6)</a>. The following code does this, simply by calling <code>rnorm()</code>. We’ll call the sample <code>lambda</code>.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="numerical-calculus.html#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> N <span class="ot">&lt;-</span> <span class="fl">1e3</span></span>
<span id="cb346-2"><a href="numerical-calculus.html#cb346-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> lambda <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">10</span>, <span class="dv">3</span>)</span></code></pre></div>
<p>By definition, <span class="math inline">\(\lambda &gt; 0\)</span>. However,</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="numerical-calculus.html#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">range</span>(lambda)</span></code></pre></div>
<pre><code>## [1] -0.5806389 19.1004557</code></pre>
<p>shows that we have some <span class="math inline">\(\lambda &lt; 0\)</span>. We’ll simply set these to zero, and proceed drawing from <span class="math inline">\(f(y \mid \mu)\)</span> with <code>rpois()</code>, storing the sample as <code>y</code>.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="numerical-calculus.html#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> y <span class="ot">&lt;-</span> <span class="fu">rpois</span>(N, <span class="fu">pmax</span>(<span class="dv">0</span>, lambda))</span></code></pre></div>
<p>We can estimate <span class="math inline">\(f(y)\)</span> from the proportion of <code>y</code> taking each of <code>y_vals</code> from Example <a href="numerical-calculus.html#exm:gqpois">4.8</a>, which we’ll store as <code>fhat3</code>.</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="numerical-calculus.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fhat3 <span class="ot">&lt;-</span> <span class="fu">sapply</span>(y_vals, <span class="cf">function</span>(z) <span class="fu">mean</span>(y <span class="sc">==</span> z))</span></code></pre></div>
<p>Finally, we’ll plot the resulting estimate alongside those of Gaussian quadrature and Laplace’s method.</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="numerical-calculus.html#cb351-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">matplot</span>(y_vals, <span class="fu">cbind</span>(fhat, fhat2, fhat3), </span>
<span id="cb351-2"><a href="numerical-calculus.html#cb351-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;y&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;f(y)&#39;</span>)</span>
<span id="cb351-3"><a href="numerical-calculus.html#cb351-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, <span class="fu">c</span>(<span class="st">&quot;Laplace&#39;s method&quot;</span>, <span class="st">&quot;Gaussian quadrature&quot;</span>, <span class="st">&quot;Monte Carlo&quot;</span>),</span>
<span id="cb351-4"><a href="numerical-calculus.html#cb351-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>        <span class="at">lty =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="main_files/figure-html/mcpois5-1.png" width="672" /></p>
<div class="remark">
<p><span id="unlabeled-div-82" class="remark"><em>Remark</em>. </span>The larger the Monte Carlo sample size, the more accurate the approximation. The following repeats Example <a href="numerical-calculus.html#exm:mcpois">4.16</a> for <span class="math inline">\(N=10^4\)</span>, <span class="math inline">\(10^5\)</span> and <span class="math inline">\(10^6\)</span>, comparing the results against <span class="math inline">\(N = 10^3\)</span>. Although we don’t have the true <span class="math inline">\(f(y)\)</span> against which to compare the Monte Carlo estimates, we are seeing in the Figure below approximations that increase with accuracy as <span class="math inline">\(N\)</span> increases.</p>
</div>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="numerical-calculus.html#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> NN <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">c</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb352-2"><a href="numerical-calculus.html#cb352-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fhat4 <span class="ot">&lt;-</span> <span class="fu">sapply</span>(NN, <span class="cf">function</span>(N) {</span>
<span id="cb352-3"><a href="numerical-calculus.html#cb352-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   lambda <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">10</span>, <span class="dv">3</span>)</span>
<span id="cb352-4"><a href="numerical-calculus.html#cb352-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   y <span class="ot">&lt;-</span> <span class="fu">rpois</span>(N, <span class="fu">pmax</span>(<span class="dv">0</span>, lambda))</span>
<span id="cb352-5"><a href="numerical-calculus.html#cb352-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="fu">sapply</span>(y_vals, <span class="cf">function</span>(z) <span class="fu">mean</span>(y <span class="sc">==</span> z))</span>
<span id="cb352-6"><a href="numerical-calculus.html#cb352-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span>
<span id="cb352-7"><a href="numerical-calculus.html#cb352-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> )</span></code></pre></div>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="numerical-calculus.html#cb353-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">matplot</span>(y_vals, fhat4, </span>
<span id="cb353-2"><a href="numerical-calculus.html#cb353-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>         <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;y&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;f(y)&#39;</span>)</span>
<span id="cb353-3"><a href="numerical-calculus.html#cb353-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, <span class="fu">paste</span>(<span class="st">&#39;N = 10^&#39;</span>, <span class="dv">3</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">sep =</span> <span class="st">&#39;&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="main_files/figure-html/mcpois8-1.png" width="672" /></p>
</div>
<div id="bibliographic-notes-2" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Bibliographic notes<a href="numerical-calculus.html#bibliographic-notes-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For details on numerical differentiation see <span class="citation">Wood (2015, sec. 5.5.2)</span> or <span class="citation">Nocedal and Wright (2006, chap. 8)</span>. For details on quadrature see <span class="citation">Monahan (2011, chap. 10)</span> or <span class="citation">Press et al. (2007, chap. 4)</span>. For details on Laplace’s method see <span class="citation">Davison (2003, sec. 11.3.1)</span>, <span class="citation">Wood (2015, sec. 5.3.1)</span> or <span class="citation">Monahan (2011, sec. 12.6)</span>. For details on Monte Carlo integration see <span class="citation">Monahan (2011, chap. 12)</span> or <span class="citation">Davison (2003, sec. 3.3)</span>.</p>
<!-- ## Exercises -->
<!-- ```{r child = 'ch4ex_child.Rmd'} -->
<!-- ``` -->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>Wikipedia has a useful pages <a href="https://en.wikipedia.org/wiki/Gaussian_quadrature">on Gaussian quadrature</a> and <a href="https://en.wikipedia.org/wiki/Legendre_polynomials">on Legendre polynomials</a>, should you want to read more on them.<a href="numerical-calculus.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Pierre-Simon Laplace (23 March 1749 – 5 March 1827) was a “French mathematician, astronomer, and physicist who was best known for his investigations into the stability of the solar system. Laplace successfully accounted for all the observed deviations of the planets from their theoretical orbits by applying Sir Isaac Newton’s theory of gravitation to the solar system, and he developed a conceptual view of evolutionary change in the structure of the solar system. He also demonstrated the usefulness of probability for interpreting scientific data”, according to Britannica.com. He developed the Laplace transform, in addition to Laplace’s method, and, with Abraham de Moivre, is responsible for the de Moivre–Laplace theorem, which approximates the binomial distribution with a normal distribution.<a href="numerical-calculus.html#fnref8" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="matrix-based-computing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="optimisation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
